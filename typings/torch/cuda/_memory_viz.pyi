"""
This type stub file was generated by pyright.
"""

from typing import Any

cache = ...
__all__ = ["format_flamegraph", "segments", "memory", "compare"]
def format_flamegraph(flamegraph_lines, flamegraph_script=...): # -> str:
    ...

def segments(snapshot, format_flamegraph=...):
    ...

def memory(snapshot, format_flamegraph=...):
    ...

def compare(before, after, format_flamegraph=...):
    ...

class Bytes:
    def __init__(self, value) -> None:
        ...
    
    def __add__(self, rhs): # -> Bytes:
        ...
    
    def __repr__(self): # -> str:
        ...
    


def calc_active(seg): # -> int:
    ...

PAGE_SIZE = ...
legend = ...
def segsum(data): # -> str:
    r"""Visually reports how the allocator has filled its segments.

    This printout can help debug fragmentation issues since free fragments
    will appear as gaps in this printout.  The amount of free space is reported
    for each segment.
    We distinguish between internal free memory which occurs because the
    allocator rounds the allocation size, and external free memory, which are
    the gaps between allocations in a segment.
    Args:
        data: snapshot dictionary created from _snapshot()
    """
    ...

def trace(data): # -> str:
    ...

_memory_viz_template = ...
def trace_plot(data, device=..., plot_segments=...): # -> str:
    """Generate a visualization over time of the memory usage recorded by the trace as an html file.

    Args:
        data: Memory snapshot as generated from torch.cuda.memory._snapshot()
        device (torch.device, optional): Generate the trace for this device, needed if multiple devices have allocations.
        plot_segments (bool, optional): Plots memory returned from cudaMalloc, rather than individual allocations.
                                        Defaults to False.

    Returns:
        str: HTML of visualization
    """
    ...

def profile_plot(profile, device=...): # -> str:
    """Generate a visualization over time of the memory usage recorded by kineto memory profiling as an html file.

    Args:
        profile: profile as generated by `torch.profiler.profile(profile_memory=True)`
        device (torch.device, optional): Generate the trace for this device, needed if multiple devices have allocations.

    Returns:
        str: HTML of visualization
    """
    ...

def segment_plot(data: Any, device=...): # -> str:
    ...

if __name__ == "__main__":
    thedir = ...
    fn_name = ...
    pickled = ...
    parser = ...
    subparsers = ...
    description = ...
    stats_a = ...
    description = ...
    trace_a = ...
    description = ...
    segments_a = ...
    description = ...
    memory_a = ...
    description = ...
    compare_a = ...
    plots = ...
    args = ...

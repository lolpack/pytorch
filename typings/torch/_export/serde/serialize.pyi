"""
This type stub file was generated by pyright.
"""

import dataclasses
import json
import sympy
import torch
import torch.export.exported_program as ep
from collections.abc import Iterator
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Any, Callable, Optional, Union, final
from torch._subclasses.fake_tensor import FakeTensor
from torch.fx._symbolic_trace import _ConstantAttributeType
from torch.fx.experimental import symbolic_shapes
from torch.utils._sympy.value_ranges import ValueRanges
from .schema import Argument, ConstantValue, CustomObjArgument, Device, ExportedProgram, Graph, GraphModule, GraphSignature, InputSpec, ModuleCallEntry, ModuleCallSignature, NamedArgument, Node, OutputSpec, RangeConstraint, SymBool, SymFloat, SymFloatArgument, SymInt, SymIntArgument, TensorArgument, TensorMeta

__all__ = ["serialize", "GraphModuleSerializer", "ExportedProgramSerializer", "GraphModuleDeserializer", "ExportedProgramDeserializer"]
log = ...
class SerializeError(RuntimeError):
    ...


MetaType = Union[FakeTensor, int, torch.SymInt, float, torch.SymFloat, bool, torch.SymBool, ep.CustomObjArgument,]
DEFAULT_PICKLE_PROTOCOL = ...
ST_DELIMITER = ...
_TORCH_TO_SERIALIZE_DTYPE = ...
_SERIALIZE_TO_TORCH_DTYPE = ...
_TORCH_TO_SERIALIZE_LAYOUT = ...
_SERIALIZE_TO_TORCH_LAYOUT = ...
_TORCH_TO_SERIALIZE_MEMORY_FORMAT = ...
_SERIALIZE_TO_TORCH_MEMORY_FORMAT = ...
_SYM_OPS = ...
@dataclass
class SerializedArtifact:
    exported_program: bytes
    state_dict: bytes
    constants: bytes
    example_inputs: bytes
    ...


@dataclass
class _SerializedProgram:
    exported_program: ExportedProgram
    state_dict: bytes
    constants: bytes
    example_inputs: bytes
    ...


def deserialize_device(d: Device) -> torch.device:
    ...

def serialize_sym_int(s: Union[int, torch.SymInt]) -> SymInt:
    ...

def serialize_sym_float(s: Union[float, torch.SymFloat]) -> SymFloat:
    ...

def serialize_sym_bool(s: Union[bool, torch.SymBool]) -> SymBool:
    ...

def serialize_tensor_meta(t: torch.Tensor) -> TensorMeta:
    """
    Extract a TensorMeta describing `t`.
    """
    ...

_CURRENT_DESERIALIZER: Optional[GraphModuleDeserializer] = ...
def serialize_torch_artifact(artifact: Optional[Any], pickle_protocol: int = ...) -> bytes:
    ...

def deserialize_torch_artifact(serialized: Union[dict[str, Any], tuple[Any, ...], bytes]): # -> dict[str, Any] | tuple[Any, ...] | dict[Any, Any]:
    ...

def serialize_range_constraints(range_constraints: dict[sympy.Symbol, ValueRanges]) -> dict[str, RangeConstraint]:
    ...

@dataclass
class GraphState:
    inputs: list[Argument] = ...
    outputs: list[Argument] = ...
    nodes: list[Node] = ...
    tensor_values: dict[str, TensorMeta] = ...
    sym_int_values: dict[str, SymInt] = ...
    sym_bool_values: dict[str, SymBool] = ...
    sym_float_values: dict[str, SymFloat] = ...
    is_single_tensor_return: bool = ...
    custom_obj_values: dict[str, CustomObjArgument] = ...


class Final(type):
    def __new__(metacls, name, bases, classdict): # -> Self:
        ...
    


@final
class GraphModuleSerializer(metaclass=Final):
    def __init__(self, graph_signature: ep.ExportGraphSignature, module_call_graph: list[ep.ModuleCallEntry]) -> None:
        ...
    
    @contextmanager
    def save_graph_state(self): # -> Generator[None, Any, None]:
        ...
    
    def handle_placeholder(self, node: torch.fx.Node): # -> None:
        ...
    
    def handle_output(self, node: torch.fx.Node): # -> None:
        ...
    
    def serialize_operator(self, target) -> str:
        ...
    
    def handle_call_function(self, node: torch.fx.Node): # -> None:
        ...
    
    def handle_get_attr(self, node): # -> None:
        ...
    
    def serialize_metadata(self, node: torch.fx.Node) -> dict[str, str]:
        ...
    
    def serialize_script_obj_meta(self, script_obj_meta: ep.CustomObjArgument) -> CustomObjArgument:
        ...
    
    def serialize_sym_op_inputs(self, op, args) -> list[NamedArgument]:
        ...
    
    def serialize_inputs(self, target: Any, args, kwargs=...) -> list[NamedArgument]:
        ...
    
    def serialize_hoo_inputs(self, args, kwargs) -> list[NamedArgument]:
        """
        For serializing HOO inputs since HOOs do not have a schema.
        """
        ...
    
    def is_inductor_sym_int_arg(self, arg) -> bool:
        ...
    
    def is_sym_int_arg(self, arg) -> bool:
        ...
    
    def is_sym_float_arg(self, arg) -> bool:
        ...
    
    def is_sym_bool_arg(self, arg) -> bool:
        ...
    
    def serialize_input(self, arg, arg_type: Optional[Any] = ...) -> Argument:
        ...
    
    def serialize_tensor_output(self, name, meta_val) -> TensorArgument:
        ...
    
    def serialize_sym_int_output(self, name, meta_val) -> SymIntArgument:
        ...
    
    def serialize_sym_float_output(self, name, meta_val) -> SymFloatArgument:
        ...
    
    def serialize_sym_bool_output(self, name, meta_val) -> SymIntArgument:
        ...
    
    def serialize_input_spec(self, spec: ep.InputSpec) -> InputSpec:
        ...
    
    def serialize_output_spec(self, spec: ep.OutputSpec) -> OutputSpec:
        ...
    
    def serialize_signature(self, sig: ep.ExportGraphSignature) -> GraphSignature:
        ...
    
    def serialize_argument_spec(self, x: ep.ArgumentSpec) -> Argument:
        ...
    
    def serialize_treespec(self, treespec): # -> str:
        ...
    
    def serialize_module_call_signature(self, module_call_signature: ep.ModuleCallSignature) -> ModuleCallSignature:
        ...
    
    def serialize_module_call_graph(self, module_call_graph: list[ep.ModuleCallEntry]) -> list[ModuleCallEntry]:
        ...
    
    def serialize_outputs(self, node: torch.fx.Node) -> list[Argument]:
        """For a given node, return the dataclass representing its output values.

        [NOTE: Multiple outputs] We handle aggregates differently than FX. For
        FX, it looks like:

            x = call_function("multiple_return", ...)
            element0 = call_function(getitem, x, 0)
            foo = call_function("use_output", element0)

        We do not want the intermediate `getitem` call, so our serialized thing looks like:

            element0, element1, element2 = call_function("multiple_return", ...)
            foo = call_function("use_output", element0)

        We want names to be consistent across these two schemes, so that we can
        mostly reuse the names coming from FX. This function computes a mapping from
        the FX representation to our representation, preserving the names.
        """
        ...
    
    def serialize_hoo_outputs(self, node: torch.fx.Node) -> list[Argument]:
        """
        For serializing HOO outputs since HOOs do not have a schema.
        """
        ...
    
    def serialize_output(self, name: str, meta_val: Any) -> Argument:
        ...
    
    def serialize_graph(self, graph_module: torch.fx.GraphModule) -> Graph:
        ...
    
    def serialize_graph_module_metadata(self, meta: dict[str, Any]): # -> dict[Any, Any]:
        ...
    
    def serialize(self, graph_module: torch.fx.GraphModule) -> GraphModule:
        ...
    


@final
class ExportedProgramSerializer(metaclass=Final):
    def __init__(self, opset_version: Optional[dict[str, int]] = ..., pickle_protocol: int = ...) -> None:
        ...
    
    def serialize(self, exported_program: ep.ExportedProgram) -> _SerializedProgram:
        """
        Args:
            exported_program: Exported Program to serialize
        """
        ...
    


@final
class GraphModuleDeserializer(metaclass=Final):
    @dataclasses.dataclass
    class Result:
        graph_module: torch.fx.GraphModule
        signature: ep.ExportGraphSignature
        module_call_graph: list[ep.ModuleCallEntry]
        names_to_symbols: dict[str, sympy.Symbol]
        state_dict: dict[str, Union[torch.Tensor, torch.nn.Parameter]]
        constants: dict[str, _ConstantAttributeType]
        example_inputs: Optional[tuple[tuple[torch.Tensor, ...], dict[str, Any]]]
        ...
    
    
    def __init__(self) -> None:
        ...
    
    @contextmanager
    def save_graph_module(self) -> Iterator[None]:
        ...
    
    def deserialize_extension_operator(self, serialized_target: str):
        ...
    
    def deserialize_operator(self, serialized_target: str): # -> str | Any:
        ...
    
    def deserialize_sym_int(self, s: SymInt) -> Union[int, torch.SymInt]:
        ...
    
    def deserialize_sym_float(self, s: SymFloat) -> Union[float, torch.SymFloat]:
        ...
    
    def deserialize_sym_bool(self, s: SymBool) -> Union[bool, torch.SymBool]:
        ...
    
    def deserialize_tensor_meta(self, tensor_meta: TensorMeta) -> FakeTensor:
        ...
    
    def deserialize_script_obj_meta(self, script_obj_meta: CustomObjArgument) -> ep.CustomObjArgument:
        ...
    
    def deserialize_graph_output(self, output) -> Optional[Union[torch.fx.Node, int]]:
        ...
    
    def deserialize_graph(self, serialized_graph: Graph) -> torch.fx.Graph:
        ...
    
    def deserialize_node(self, serialized_node: Node, target: Callable) -> None:
        ...
    
    def deserialize_input_spec(self, i: InputSpec) -> ep.InputSpec:
        ...
    
    def deserialize_output_spec(self, o: OutputSpec) -> ep.OutputSpec:
        ...
    
    def deserialize_signature(self, sig: GraphSignature) -> ep.ExportGraphSignature:
        ...
    
    def deserialize(self, serialized_graph_module: GraphModule, serialized_state_dict: Union[dict[str, torch.Tensor], bytes], constants: Union[dict[str, Any], bytes], example_inputs: Optional[Union[tuple[tuple[torch.Tensor, ...], dict[str, Any]], bytes]] = ..., symbol_name_to_range: Optional[dict[str, symbolic_shapes.ValueRanges]] = ...) -> Result:
        ...
    
    def sync_fx_node(self, name: str, fx_node: torch.fx.Node): # -> None:
        ...
    
    def deserialize_sym_op_inputs(self, inputs): # -> tuple[Any, ...]:
        ...
    
    def deserialize_inputs(self, target, serialized_node: Node): # -> tuple[tuple[Any, ...], OrderedDict[str, Any]]:
        ...
    
    def deserialize_hoo_inputs(self, inputs: list[NamedArgument]): # -> tuple[tuple[Any, ...], dict[Any, Any]]:
        """
        For deserializing HOO inputs since HOOs do not have a schema.
        """
        ...
    
    def deserialize_input(self, inp: Argument) -> Any:
        ...
    
    def deserialize_constant_input(self, inp: ConstantValue) -> Any:
        ...
    
    def deserialize_sym_argument(self, sym_arg): # -> int | Node | float | bool:
        ...
    
    def deserialize_sym_op_outputs(self, serialized_node: Node, fx_node: torch.fx.Node): # -> None:
        ...
    
    def deserialize_outputs(self, serialized_node: Node, fx_node: torch.fx.Node): # -> None:
        ...
    
    def generate_getitem(self, meta_val, fx_node: torch.fx.Node, arg: Union[TensorArgument, SymIntArgument, SymFloatArgument], idx: int, deserialized_metadata: dict[str, Any]): # -> None:
        ...
    
    def generate_getitems(self, meta_val, fx_node: torch.fx.Node, args, deserialized_metadata: dict[str, Any]): # -> None:
        ...
    
    def deserialize_multiple_outputs(self, serialized_node: Node, fx_node: torch.fx.Node) -> None:
        ...
    
    def deserialize_metadata(self, metadata: dict[str, str]) -> dict[str, Any]:
        ...
    
    def deserialize_argument_spec(self, x: Argument) -> ep.ArgumentSpec:
        ...
    
    def deserialize_module_call_signature(self, module_call_signature: ModuleCallSignature) -> ep.ModuleCallSignature:
        ...
    
    def deserialize_module_call_graph(self, module_call_graph: list[ModuleCallEntry]) -> list[ep.ModuleCallEntry]:
        ...
    


@final
class ExportedProgramDeserializer(metaclass=Final):
    def __init__(self, expected_opset_version: Optional[dict[str, int]] = ...) -> None:
        ...
    
    def deserialize_range_constraints(self, symbol_name_to_range: dict[str, symbolic_shapes.ValueRanges], symbol_name_to_symbol: dict[str, sympy.Symbol]) -> dict[sympy.Symbol, ValueRanges]:
        ...
    
    def deserialize(self, exported_program: ExportedProgram, state_dict: Union[dict[str, torch.Tensor], bytes], constants: Union[dict[str, torch.Tensor], bytes], example_inputs: Optional[Union[tuple[tuple[torch.Tensor, ...], dict[str, Any]], bytes]] = ..., *, _unsafe_skip_version_check=...) -> ep.ExportedProgram:
        ...
    


class EnumEncoder(json.JSONEncoder):
    def default(self, obj): # -> Any | str:
        ...
    


def serialize(exported_program: ep.ExportedProgram, opset_version: Optional[dict[str, int]] = ..., pickle_protocol: int = ...) -> SerializedArtifact:
    ...

def deserialize(artifact: SerializedArtifact, expected_opset_version: Optional[dict[str, int]] = ..., *, _unsafe_skip_version_check=...) -> ep.ExportedProgram:
    ...

def canonicalize(ep: ExportedProgram, constants: Optional[set[str]] = ...) -> ExportedProgram:
    """
    Normalize a serialized ExportedProgram, so that different eager program which
    shares the same semantics can get a single representation on disk.

    This function canonicalizes an ExportedProgram by:

    1. Sorting nodes in topological order.
    2. Rename nodes to have unique names.
    3. Remove unstable fields.
    4. Aggregate the above program fields.
    5. Recurse in subgraphs.

    Args:
        ep (ExportedProgram): The ExportedProgram to canonicalize.
        constants (Optional[set[str]]): Set of constants names

    Returns:
        ExportedProgram: The canonicalized exported program.
    """
    ...

class ExtensionHandler:
    """
    Base class for handling extension operators.
    """
    @classmethod
    def namespace(cls) -> str:
        ...
    
    @classmethod
    def to_op_name(cls, op) -> str:
        ...
    
    @classmethod
    def from_op_name(cls, name: str):
        ...
    
    @classmethod
    def op_schema(cls, op) -> torch.FunctionSchema:
        ...
    


def register_extension(op_type: type[Any], extension_handler: type[ExtensionHandler]): # -> None:
    """Register custom de/serialization method for a node with non-standard type."""
    ...

_serialization_registry: dict[type[Any], type[ExtensionHandler]] = ...
_deserialization_registry: dict[str, type[ExtensionHandler]] = ...

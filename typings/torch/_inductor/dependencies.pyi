"""
This type stub file was generated by pyright.
"""

import abc
import dataclasses
import sympy
import torch
from collections.abc import Iterable, Sequence
from typing import Any, Callable, Optional, TypeVar, Union
from typing_extensions import Self
from torch.utils._ordered_set import OrderedSet
from .ops_handler import DefaultHandler
from .utils import VarRanges
from .virtualized import ReductionType, V

T = TypeVar("T")
log = ...
is_indirect = ...
class Dep(abc.ABC):
    name: str
    index: sympy.Expr
    @abc.abstractmethod
    def rename(self, renames: dict[str, str]) -> Self:
        ...
    
    @abc.abstractmethod
    def get_numel(self) -> sympy.Expr:
        ...
    
    @abc.abstractmethod
    def numbytes_hint(self) -> int:
        ...
    
    @abc.abstractmethod
    def has_unbacked_symbols(self) -> bool:
        ...
    
    @abc.abstractmethod
    def is_contiguous(self) -> bool:
        ...
    
    def normalize_with_stride_order(self, prefix: str = ...) -> Self:
        ...
    


@dataclasses.dataclass(frozen=True)
class MemoryDep(Dep):
    name: str
    index: sympy.Expr
    var_names: tuple[sympy.Symbol, ...]
    size: tuple[sympy.Expr, ...]
    mode: Optional[str] = ...
    def __repr__(self) -> str:
        ...
    
    @property
    def num_vars(self) -> int:
        ...
    
    def decide_loop_order_to_match(self, other: MemoryDep) -> Optional[list[int]]:
        """
        Can return None if not able to decide loop orders.
        """
        ...
    
    def get_offset(self) -> sympy.Expr:
        """
        Return the offset by setting every variable to be 0.
        """
        ...
    
    def normalize(self) -> MemoryDep:
        """
        Normalize by merging loops. The different to normalize_with_stride_order is,
        this method does not reorder loops while normalize_with_stride_order reorder
        loops based on stride order.
        """
        ...
    
    def normalize_with_stride_order(self, prefix: str = ...) -> MemoryDep:
        r"""
        Used to decide if two MemoryDep does not equal due to different loop orders.
        More specifically, when dep1 and dep2 are not equal, we can normalize
        both and check if they are equal after that. If yes, then the mismatch is
        caused by different loop orders.
        """
        ...
    
    @property
    def ranges(self) -> dict[sympy.Symbol, sympy.Expr]:
        """{c0: 128, c1: 512, ...}"""
        ...
    
    def simplify_with_ranges(self) -> MemoryDep:
        ...
    
    def get_numel(self) -> sympy.Expr:
        ...
    
    def rename(self, renames: dict[str, str]) -> MemoryDep:
        ...
    
    def numbytes_hint(self) -> int:
        ...
    
    def has_unbacked_symbols(self) -> bool:
        ...
    
    def is_contiguous(self) -> bool:
        ...
    
    def stride1_for_last_dim(self, result_for_complex_expression: bool = ...) -> bool:
        """
        Whether the stride for the last dimension is 1.
        """
        ...
    
    def is_scalar(self) -> bool:
        ...
    
    def is_indirect(self) -> bool:
        ...
    


@dataclasses.dataclass(frozen=True)
class StarDep(Dep):
    name: str
    mode: Optional[str] = ...
    @property
    def index(self) -> sympy.Expr:
        ...
    
    def get_numel(self) -> sympy.Expr:
        ...
    
    def rename(self, renames: dict[str, str]) -> StarDep:
        ...
    
    def numbytes_hint(self) -> int:
        ...
    
    def has_unbacked_symbols(self) -> bool:
        ...
    
    def is_contiguous(self) -> bool:
        ...
    
    def is_scalar(self) -> bool:
        ...
    
    def is_indirect(self) -> bool:
        ...
    


@dataclasses.dataclass(frozen=True)
class WeakDep(Dep):
    name: str
    mutating_buf: str
    @property
    def index(self) -> sympy.Expr:
        ...
    
    def get_numel(self) -> sympy.Expr:
        ...
    
    def rename(self, renames: dict[str, str]) -> WeakDep:
        ...
    
    def numbytes_hint(self) -> int:
        ...
    
    def has_unbacked_symbols(self) -> bool:
        ...
    
    def is_contiguous(self) -> bool:
        ...
    


@dataclasses.dataclass(frozen=True)
class IndexExprDep:
    index: sympy.Expr
    var_names: tuple[sympy.Symbol, ...]
    size: tuple[sympy.Expr, ...]
    ...


@dataclasses.dataclass
class ReadWrites:
    reads: OrderedSet[Dep]
    writes: OrderedSet[Dep]
    index_exprs: OrderedSet[IndexExprDep]
    range_vars: Optional[list[sympy.Expr]] = ...
    var_ranges: Optional[VarRanges] = ...
    def rename(self, renames: dict[str, str]) -> ReadWrites:
        ...
    
    def with_read(self, dep: Union[Dep, OrderedSet[Dep]]) -> ReadWrites:
        ...
    
    def merge(self, other: ReadWrites) -> ReadWrites:
        ...
    
    @staticmethod
    def merge_list(read_writes: list[ReadWrites]) -> ReadWrites:
        ...
    
    def remove_reads(self, rem_reads: OrderedSet[Dep]) -> ReadWrites:
        ...
    
    def reads_and_writes(self) -> Iterable[Dep]:
        ...
    
    def buffer_names(self, ignore_integer_index: bool = ...) -> OrderedSet[str]:
        """
        Integer index is used for load_seed.
        """
        ...
    


class _RecordLoadStoreInner(V.MockHandler):
    def __init__(self, var_ranges: VarRanges, normalize: bool) -> None:
        ...
    
    @staticmethod
    def drop_unused_symbols(index: Union[int, sympy.Expr], var_names: list[sympy.Expr], sizes: list[sympy.Expr]) -> None:
        """
        Reduction has last (reduced) dim in its sizes, but
        downstream users won't.  Normalize this away.
        """
        ...
    
    def canonicalize(self, index: sympy.Expr) -> tuple[sympy.Expr, tuple[sympy.Symbol, ...], tuple[sympy.Expr, ...]]:
        ...
    
    def load(self, name: str, index: sympy.Expr) -> str:
        ...
    
    def load_seed(self, name: str, index: int) -> str:
        ...
    
    def store(self, name: str, index: sympy.Expr, value: str, mode: Optional[str] = ...) -> str:
        ...
    
    def store_reduction(self, name: str, index: sympy.Expr, value: str) -> str:
        ...
    
    def index_expr(self, index: sympy.Expr, dtype: Optional[torch.dtype]) -> str:
        ...
    
    def bucketize(self, values: T, boundaries: tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: T, indexing_dtype: torch.dtype, right: bool, sorter: Optional[tuple[str, sympy.Expr]] = ..., sorter_indices: Optional[T] = ...) -> None:
        """Records the names of the buffers that bucketize will read from."""
        ...
    


class RecordLoadStore(V.KernelFormatterHandler):
    def __init__(self, var_ranges: VarRanges, normalize: bool) -> None:
        ...
    


def var_builder(prefix: str) -> tuple[VarRanges, Callable[[sympy.Expr], sympy.Symbol]]:
    ...

def index_vars_no_squeeze(*argsizes: Sequence[sympy.Expr], prefix: str) -> tuple[list[list[sympy.Symbol]], VarRanges]:
    ...

def index_vars_squeeze(*argsizes: Sequence[sympy.Expr], prefix: str = ...) -> tuple[list[list[sympy.Expr]], VarRanges]:
    ...

def extract_read_writes(fn: Callable[..., Any], *argsizes: Sequence[sympy.Expr], normalize: bool = ..., prefix: str = ..., hidden_args: Sequence[list[sympy.Expr]] = ...) -> ReadWrites:
    ...

def extract_loop_body_with_args(fn: Any, args: list[list[sympy.Expr]], var_ranges: VarRanges, normalize: bool = ...) -> _RecordLoadStoreInner:
    ...

def extract_input_node_reduction_ranges(input_node: torch._inductor.ir.IRNode) -> tuple[Optional[list[sympy.Expr]], Optional[list[sympy.Expr]]]:
    """
    Returns the size and reduction size of all inputs, if the sizes and reduction_sizes (if exist) are all the same.
    It's possible that a node has multiple inputs, some are Reduction nodes and others are Pointwise nodes.
    In this case, reduction_sizes of the Reduction nodes need to be the same.
    Otherwise returns (None, None).
    """
    ...

def canonicalization_prefix() -> str:
    ...

class FreeSymbolsOpsHandler(DefaultHandler):
    symbols: OrderedSet[sympy.Symbol]
    def __init__(self, unbacked_only: bool = ...) -> None:
        ...
    
    def indirect_indexing(self, index_var: Any, size: Union[int, sympy.Expr], check: bool = ..., wrap_neg: bool = ...) -> sympy.Symbol:
        ...
    
    def frexp(self, x: Any) -> tuple[None, ...]:
        ...
    
    def scan(self, dtypes: Any, combine_fn: Any, values: Sequence[Any]) -> tuple[None, ...]:
        ...
    
    def sort(self, dtypes: Any, values: Sequence[Any], stable: Any, descending: Any) -> tuple[None, ...]:
        ...
    
    def reduction(self, dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Union[None, tuple[None, ...]]) -> Union[None, tuple[None, ...]]:
        ...
    
    def masked(self, mask: Any, body: Callable[..., Any], other: Any) -> None:
        ...
    


def extract_free_symbols(fn: Callable[..., Any], index: Sequence[sympy.Expr], rindex: Optional[Sequence[sympy.Expr]] = ..., unbacked_only: bool = ...) -> OrderedSet[sympy.Symbol]:
    ...


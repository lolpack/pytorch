"""
This type stub file was generated by pyright.
"""

import torch
from ..pattern_matcher import CallFunctionVarArgs, Match, register_graph_pattern

log = ...
patterns = ...
aten = ...
def replace_random_passes(gm: torch.fx.GraphModule): # -> int:
    """Modify the given FX graph to use backend-native random ops"""
    ...

def fuse_seed_creation_pass(graph: torch.fx.Graph): # -> int:
    """
    Horizontally fuse all the seed generation on each device

        a = inductor_seed(dev)
        b = inductor_seed(dev)

    Becomes:
        seeds = inductor_seeds(2, dev)
        a = inductor_lookup_seed(seeds, 0)
        b = inductor_lookup_seed(seeds, 1)

    We do this because seed creation is entirely launch overhead bound.
    """
    ...

def default_kwargs(device): # -> dict[Any, Any]:
    ...

def get_device(device): # -> device:
    ...

@register_graph_pattern(CallFunctionVarArgs(aten.rand.default), pass_dict=patterns)
@register_graph_pattern(CallFunctionVarArgs(aten.rand.generator), pass_dict=patterns)
@register_graph_pattern(CallFunctionVarArgs(aten.randn.default), pass_dict=patterns)
@register_graph_pattern(CallFunctionVarArgs(aten.randn.generator), pass_dict=patterns)
def replace_random(match: Match, size, *, generator=..., dtype=..., device=..., layout=..., pin_memory=...): # -> None:
    ...

@register_graph_pattern(CallFunctionVarArgs(aten.randint.low), pass_dict=patterns)
def replace_randint(match: Match, low, high, size, *, dtype=..., device=..., layout=..., pin_memory=...): # -> None:
    ...


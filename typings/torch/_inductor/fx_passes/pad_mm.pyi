"""
This type stub file was generated by pyright.
"""

import functools
import torch
from collections.abc import Sequence
from typing import Any, Callable, Optional, Union
from torch import Tensor
from torch._inductor.autoheuristic.autoheuristic import AHContext
from ..pattern_matcher import Match

aten = ...
_skip_do_bench_times = ...
def fetch_fake_tensors(match: Match, kwarg_names: Sequence[str]) -> list[Tensor]:
    ...

def unwrap_fake_args(*arg_names: str) -> Callable[[Callable[..., Any]], Callable[[Match], Any]]:
    ...

def get_alignment_size(x: Tensor) -> int:
    ...

def get_alignment_size_dtype(dtype: torch.dtype) -> int:
    ...

def check_device(a: Tensor, b: Tensor) -> bool:
    ...

def check_dtype(a: Tensor, b: Tensor) -> bool:
    ...

def should_pad_common(mat1: Tensor, mat2: Tensor, input: Optional[Tensor] = ...) -> bool:
    ...

def get_padded_length(x: Union[int, torch.SymInt], alignment_size: int) -> int:
    ...

def pad_dim(x: Tensor, padded_length: int, dim: int) -> Tensor:
    ...

def addmm_pattern(input: Tensor, mat1: Tensor, mat2: Tensor, beta: float, alpha: float) -> Tensor:
    ...

def should_pad_addmm(match: Match) -> bool:
    ...

def pad_addmm(input: Optional[Tensor], mat1: Tensor, mat2: Tensor, m_padded_length: int, k_padded_length: int, n_padded_length: int, beta: float = ..., alpha: float = ..., mat1_pre_padded: bool = ..., mat2_pre_padded: bool = ...) -> Tensor:
    ...

def addmm_replace(input: Optional[Tensor], mat1: Tensor, mat2: Tensor, beta: float = ..., alpha: float = ...) -> Tensor:
    ...

def is_mm_compute_bound(M: int, K: int, N: int, dtype: torch.dtype) -> bool:
    ...

@functools.cache
def get_pad_cache() -> torch._inductor.codecache.LocalCache:
    ...

def get_cached_should_pad(key: str) -> bool:
    ...

def set_cached_should_pad(key: str, value: bool) -> None:
    ...

def get_cached_base_mm_benchmark_time(key: str) -> float:
    ...

def set_cached_base_mm_benchmark_time(key: str, value: float) -> None:
    ...

def should_pad_bench_key(match: Match, mat1: Tensor, mat2: Tensor, op: torch._ops.OpOverloadPacket, input: Optional[Tensor] = ..., is_base_time_key: bool = ...) -> str:
    ...

def get_non_view_def(node: torch.fx.Node) -> torch.fx.Node:
    ...

def should_exclude_padding_time(match: Match, arg_name: str) -> bool:
    ...

def should_pad(key: str, ori_time: float, pad_time: float) -> bool:
    ...

def should_pad_mm_bf16(dtype: torch.dtype, M: int, N: int, K: int) -> bool:
    ...

def should_pad_bench(*args: Any, **kwargs: Any) -> bool:
    ...

def get_do_bench() -> Callable[[Callable[[], Any]], float]:
    ...

def get_context(mat1: Tensor, mat2: Tensor, mat1_pre_padded: bool, mat2_pre_padded: bool, m_padded_length: int, k_padded_length: int, n_padded_length: int) -> AHContext:
    ...

def run_autoheuristic(mat1: Tensor, mat2: Tensor, orig_bench_fn: Callable[[], None], pad_bench_fn: Callable[[], None], m_padded_length: int, k_padded_length: int, n_padded_length: int, do_bench: Callable[[Callable[[], Any]], float], mat1_pre_padded: bool, mat2_pre_padded: bool, ori_time: float, ori_time_key: str, key: str) -> Optional[bool]:
    ...

def mm_pattern(mat1: Tensor, mat2: Tensor) -> Tensor:
    ...

def should_pad_mm(match: Match) -> bool:
    ...

def pad_mat1(mat1: Tensor, *, m_padded_length: int, k_padded_length: int, is_bmm: bool = ...) -> Tensor:
    ...

def pad_mat2(mat2: Tensor, *, k_padded_length: int, n_padded_length: int, is_bmm: bool = ...) -> Tensor:
    ...

def pad_mm(mat1: Tensor, mat2: Tensor, m_padded_length: int, k_padded_length: int, n_padded_length: int, mat1_pre_padded: bool = ..., mat2_pre_padded: bool = ...) -> Tensor:
    ...

def mm_replace(mat1: Tensor, mat2: Tensor) -> Tensor:
    ...

def bmm_pattern(mat1: Tensor, mat2: Tensor) -> Tensor:
    ...

def should_pad_bmm(match: Match) -> bool:
    ...

def pad_bmm(mat1: Tensor, mat2: Tensor, m_padded_length: int, k_padded_length: int, n_padded_length: int, mat1_pre_padded: bool = ..., mat2_pre_padded: bool = ...) -> Tensor:
    ...

def bmm_replace(mat1: Tensor, mat2: Tensor) -> Tensor:
    ...


"""
This type stub file was generated by pyright.
"""

import torch
import torch._ops
from collections.abc import Sequence
from typing import Any, Callable, Optional, Union
from .. import ir
from .cpp_wrapper_cpu import CppWrapperCpu
from .wrapper import BufferLike, PythonWrapperCodegen

BufferName = str
MAX_STACK_ALLOCATION_SIZE = ...
class CppWrapperCpuArrayRef(CppWrapperCpu):
    """
    Generates cpp wrapper for running on CPU and calls cpp kernels

    This class is forked from CppWrapperCpu, with a difference that tensors may be
    represented as ArrayRef, see torch/csrc/inductor/aoti_runtime/arrayref_tensor.h
    """
    def __init__(self) -> None:
        ...
    
    @staticmethod
    def create(is_subgraph: bool, subgraph_name: Optional[str], parent_wrapper: Optional[PythonWrapperCodegen], partition_signatures: Optional[ir.GraphPartitionSignature] = ...): # -> CppWrapperCpuArrayRef:
        ...
    
    @staticmethod
    def get_input_cpp_type(input): # -> str:
        ...
    
    @staticmethod
    def get_device_include_path(device: str) -> str:
        ...
    
    def codegen_input_numel_asserts(self): # -> None:
        ...
    
    def generate_extern_kernel_alloc(self, *args, **kwargs): # -> None:
        ...
    
    def generate_extern_kernel_out(self, *args, **kwargs): # -> None:
        ...
    
    def generate_fallback_kernel(self, node: ir.FallbackKernel) -> None:
        ...
    
    def write_wrapper_decl(self): # -> None:
        ...
    
    def generate_return(self, output_refs: list[str]): # -> None:
        ...
    
    def memory_plan(self): # -> None:
        ...
    
    def memory_plan_reuse(self): # -> None:
        ...
    
    def can_stack_allocate_buffer(self, buffer): # -> bool:
        ...
    
    def make_buffer_free(self, buffer): # -> str:
        ...
    
    def make_buffer_allocation(self, buffer): # -> str:
        ...
    
    def make_allocation(self, name, device, dtype, shape, stride, buffer_if_can_stack_allocate=...): # -> str:
        ...
    
    def make_buffer_reuse(self, old: BufferLike, new: BufferLike, delete_old: bool): # -> str:
        ...
    
    def is_safe_to_use_borrow_arrayref_tensor_as_tensor(self): # -> bool:
        ...
    
    def generate_c_shim_extern_kernel_call(self, kernel: str, args: list[str], device: str, **_) -> None:
        ...
    
    def generate_scatter_fallback(self, output, inputs, cpp_kernel_name, python_kernel_name, src_is_tensor, reduce, kwargs): # -> None:
        ...
    
    def generate_index_put_fallback(self, kernel, x, indices, values, accumulate): # -> None:
        ...
    
    def generate_fallback_kernel_with_runtime_lookup(self, buf_name: str, python_kernel_name: str, get_args: Callable[[], Sequence[str]], op_overload: Union[torch._ops.OpOverload, torch._ops.HigherOrderOperator], raw_args: Sequence[Any], outputs: Sequence[ir.Buffer]) -> None:
        ...
    
    def codegen_device_copy(self, src, dst, non_blocking: bool): # -> None:
        ...
    
    def codegen_reinterpret_view(self, data, size, stride, offset, writeline: Callable[..., None], dtype=...) -> str:
        """Returns a newly-created, temporary RAII tensor handle containing the
        reinterpreted tensor data.  Callers of this function are responsible for saving
        the handle if persistent access is needed."""
        ...
    
    def val_to_arg_str(self, val, type_=...) -> str:
        ...
    
    def codegen_tensor_item(self, dtype: torch.dtype, tensor: str, scalar: str, indented_buffer=...): # -> None:
        ...
    



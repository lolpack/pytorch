"""
This type stub file was generated by pyright.
"""

import functools
from abc import ABC, abstractmethod
from typing import Any, Optional, Union
from torch._inductor.scheduler import BaseSchedulerNode
from torch._inductor.utils import clear_on_fresh_cache
from ... import ir
from ...ir import Buffer, CUDATemplateBuffer, ChoiceCaller, IRNode, Layout, ReinterpretView
from ..common import IndentedBuffer
from .cuda_kernel import CUDATemplateKernel
from .cuda_template import CUTLASSTemplate

GemmOperation = Any
log = ...
GEMM_TEMPLATE_CUTLASS_3X = ...
GEMM_ARGS_CUTLASS_3X = ...
GEMM_ARGS_CUTLASS_3X_EPILOGUE = ...
GEMM_TEMPLATE_CUTLASS_2X = ...
GEMM_ARGS_CUTLASS_2X = ...
GEMM_ARGS_SPARSE_CUTLASS_2X = ...
GEMM_STANDALONE_RUNNER_ADDITIONAL_INCLUDES = ...
GEMM_STANDALONE_RUNNER_TEMPLATE = ...
@clear_on_fresh_cache
class CUTLASSGemmTemplate(CUTLASSTemplate, ABC):
    """
    CUTLASS GEMM Template, which is used to generate CUTLASS GEMM kernels
    including those which allow flexible fusions with epilogues.
    """
    filtered_ops_cache: dict[str, list[Any]] = ...
    cache_clear = ...
    def __init__(self, input_nodes: list[Buffer], layout: Layout, alpha: float, beta: float, input_reorder: Optional[list[int]] = ..., use_fast_accum: Optional[bool] = ...) -> None:
        """
        Args:
            input_nodes (List[Buffer]): List of input nodes of the GEMM kernel.
            layout (Layout): Layout type of the resulting output node.
            alpha (float): The scaling factor for the product of the inputs in the GEMM operation.
            beta (float): The scaling factor applied to the output matrix.
            input_reorder (Optional[List[int]]): Specifies the reordering of the input nodes. If not provided,
                            no reordering is performed. Defaults to None.
        """
        ...
    
    @staticmethod
    @abstractmethod
    def add_cutlass_gemm_choices(choices: list[ChoiceCaller], layout: ir.Layout, input_nodes: list[Buffer], alpha: Union[float, int] = ..., beta: Union[float, int] = ..., input_reorder: Optional[list[int]] = ..., use_fast_accum: Optional[bool] = ..., **extra_kwargs) -> None:
        ...
    
    def header(self) -> IndentedBuffer:
        """
        Returns a buffer containing CUDA C++ code for the header section of the CUTLASS GEMM template.
        This section primarily includes the necessary header files.

        Returns:
            IndentedBuffer: An instance of IndentedBuffer that contains the generated CUDA C++ header code.
        """
        ...
    
    @staticmethod
    def cutlass_layout(torch_layout: ir.Layout) -> Optional[cutlass_lib.LayoutType]:
        """
        Converts an ir.Layout instance into the corresponding cutlass_library.LayoutType enum value
        (RowMajor, ColumnMajor, or None if no matching value is found ).

        Args:
            torch_layout (ir.Layout): The layout that needs to be looked up.

        Returns:
            cutlass_lib.LayoutType: The converted layout corresponding to the `torch_layout` or None if no matching
            value is found.
        """
        ...
    
    @staticmethod
    def flip_cutlass_layout(cutlass_layout: cutlass_lib.LayoutType) -> cutlass_lib.LayoutType:
        """Helper method: Flips a given cutlass layout (cutlass_lib.LayoutType) from RowMajor
        to ColumnMajor or vice versa"""
        ...
    
    @staticmethod
    @functools.lru_cache(32)
    def layout_match(torch_layout: ir.Layout, cutlass_layout: cutlass_lib.LayoutType) -> bool:
        """Helper Method: Determines whether a given torch layout matches a given Cutlass layout"""
        ...
    
    @staticmethod
    def set_alignment(torch_layout, op_element) -> bool:
        """
        Helper method to update the alignment of a given CUTLASS GEMM op operand's element.

        This method modifies the alignment of the given Cutlass GEMM op operand's element to match the
        layout of the corresponding ir.Buffer node.

        Args:
            torch_layout: The layout of the corresponding ir.Buffer node.
            op_element: The Cutlass GEMM op operand's element whose alignment is to be updated.

        Returns:
            bool: True if the alignment was successfully updated, False otherwise.
        """
        ...
    
    @staticmethod
    def should_swap_XW(bias: IRNode) -> bool:
        """
        Helper method to determine whether we should do an explicit transpose by switching the order of the
        matmul operands. This might be necessary when we can't otherwise arrive at the right memory
        layout for the given Bias operand.

        Note: This method is a workaround for CUDA Errors that seemingly non-deterministically
        occurred in practice in some CUTLASS GEMM Kernels with Linear epilogues that have a bias term.
        it might make sense to check on newer Cutlass releases whether it makes sense to keep
        returning True in certain cases or whether it becomes unnecessary.
        """
        ...
    
    @staticmethod
    def swap_XW(op: cutlass_library.gemm_op.GemmOperation) -> cutlass_library.gemm_op.GemmOperation:
        """
        Swap operands X and W (aka operans A and B) of the GEMM operation. This
        requires transposing the operands, which is done by swapping the strides.
        Note that we don't change the apparent external layout, just the operand layout.
        this is intentional.
        """
        ...
    
    def fix_op_layout(self, op: cutlass_library.gemm_op.GemmOperation, X: Buffer, W: Buffer, Bias: Optional[Buffer], Y: Union[Buffer, ReinterpretView]) -> cutlass_library.gemm_op.GemmOperation:
        ...
    
    def filter_op(self, op: cutlass_library.gemm_op.GemmOperation) -> cutlass_library.gemm_op.GemmOperation:
        """
        Helper method:

        Determines whether a given Cutlass GEMM op definition is suitable for the current
        input / output of the operation that this template is supposed to implement.

        Takes memory layout, dtype and support for EVT operations into account,
        and filters potentially problematic ops.

        Returns None if the op is not suitable, otherwise returns the op to be used, which might
        have been mutated.
        """
        ...
    
    def gen_ops(self) -> list[tuple[str, cutlass_gemm_op.GemmOperation]]:
        """
        Creates a list of Cutlass GemmOperation instances that match the operation this template is designed to represent.
        The matching is carried out with respect to the input and output specifications of the operation.

        No function arguments.

        Returns:
            List[Tuple[str, cutlass_gemm_op.GemmOperation]]: A list of (cutlass_name, GemmOperation)
            tuples that are compatible with the operation requirements of this template.
        """
        ...
    
    def gemm_mode(self) -> str:
        """
        Returns a Cutlass GEMM mode string for the current operation, dependent on whether this op implements
        a batched GEMM or a simple GEMM without batch dimension.

        Returns:
        str: A string indicating the Cutlass GEMM mode. If the output node has more than two dimensions,
            "cutlass::gemm::GemmUniversalMode::kBatched" is returned, otherwise
            "cutlass::gemm::GemmUniversalMode::kGemm" is returned.
        """
        ...
    
    def render(self, kernel: CUDATemplateKernel, op: cutlass_gemm_op.GemmOperation = ..., template_buffer_node: Optional[CUDATemplateBuffer] = ..., epilogue_nodes: Optional[list[BaseSchedulerNode]] = ..., **kwargs) -> str:
        """
        The primary entry point for the code rendering process used in this template.
        Renders the Cutlass based CUDA C++ code for the GEMM Kernel that this template is designed to implement,
        including potentially fused epilogues.

        Args:
            kernel (CUDATemplateKernel): The kernel to be rendered.
            op (cutlass_gemm_op.GemmOperation, optional): A GEMM operation that is required to be compatible with the
                input and output definitions as well as a possible epilogue. Defaults to None.
            **kwargs: Additional keyword arguments. Currently unused.

        Returns:
            str: Cutlass based CUDA C++ code fragment as a string, to be used by the current
            CUDATemplateKernel or autotuning code.

        Note:
            All inputs and their corresponding buffer addresses and names take precedence over previously
            passed inputs to the template at construction time. However, they should be layout compatible.
        """
        ...
    
    def test_call_statement(self, kernel, input_nodes, names_str: str = ...) -> str:
        """
        Helper method to render the Cutlass CUDA C++ code required for calling the GEMM operation in the standalone
        test runner that might also be generated along with the rest of the code, if the corresponding config is
        enabled.

        Returns a C++ statement that calls the GEMM operation with the correct arguments.
        """
        ...
    


class CUTLASS3xGemmTemplate(CUTLASSGemmTemplate):
    """
    CUTLASS 3x GEMM Template, which is used to generate CUTLASS GEMM kernels
    including those which allow flexible fusions with epilogues.
    """
    def __init__(self, input_nodes: list[Buffer], layout: Layout, alpha: float, beta: float, input_reorder: Optional[list[int]] = ..., use_fast_accum: Optional[bool] = ...) -> None:
        ...
    
    @staticmethod
    def add_cutlass_gemm_choices(choices: list[ChoiceCaller], layout: ir.Layout, input_nodes: list[Buffer], alpha: Union[float, int] = ..., beta: Union[float, int] = ..., input_reorder: Optional[list[int]] = ..., use_fast_accum: Optional[bool] = ..., **extra_kwargs) -> None:
        ...
    
    @staticmethod
    def supports_epilogue_fusion(op: GemmOperation) -> bool:
        ...
    
    def render_gemm_arguments(self, argument_template: str, epilogue_template: str, should_swap_xw: bool, X: IRNode, W: IRNode, Bias: IRNode, Y: IRNode, alpha: float, beta: float, kernel: CUDATemplateKernel, epilogue_args) -> str:
        """
        Render the Cutlass CUDA C++ code required for passing arguments to the GEMM operation.

        Args:
            argument_template (str): Template for the GEMM operation arguments.
            epilogue_template (str): Template for the epilogue arguments.
            should_swap_xw (bool): Determines whether X, W operands should be swapped. If True, applies an explicit
            transpose operation to X and W.
            X (IRNode): The X input tensor.
            W (IRNode): The W input tensor.
            Bias (IRNode): The bias tensor.
            Y (IRNode): The output tensor.
            alpha (float): Scaling factor for the product of the inputs.
            beta (float): Scaling factor for the output tensor.
            kernel (CUDATemplateKernel): CUDA Template kernel for the operation.
            epilogue_args (any): Additional arguments for the epilogue state.

        Returns:
            str: A block of CUDA C++ code as a string, ready to be used as arguments for the GEMM operation.

        Note: If `should_swap_xw` is True, a transpose operation will be applied to the X, W, Bias, and Y
        tensors. This operation also implies the M and N dimensions of Bias and GEMM output to be swapped
        before the function call.
        """
        ...
    


class CUTLASS2xGemmTemplate(CUTLASSGemmTemplate):
    def __init__(self, input_nodes: list[Buffer], layout: Layout, alpha: float, beta: float, input_reorder: Optional[list[int]] = ...) -> None:
        ...
    
    @staticmethod
    def add_cutlass_gemm_choices(choices: list[ChoiceCaller], layout: ir.Layout, input_nodes: list[Buffer], alpha: Union[float, int] = ..., beta: Union[float, int] = ..., input_reorder: Optional[list[int]] = ..., use_fast_accum: Optional[bool] = ..., **extra_kwargs) -> None:
        ...
    
    def render_gemm_arguments(self, instance_type: str, argument_template: str, epilogue_template: str, should_swap_xw: bool, X: IRNode, W: IRNode, Bias: IRNode, Meta: IRNode, Y: IRNode, alpha: float, beta: float, kernel: CUDATemplateKernel, epilogue_args) -> str:
        """
        Render the Cutlass CUDA C++ code required for passing arguments to the GEMM operation.

        Args:
            instance_type (str): GEMM instance type.
            argument_template (str): Template for the GEMM operation arguments.
            epilogue_template (str): Template for the epilogue arguments.
            should_swap_xw (bool): Determines whether X, W operands should be swapped. If True, applies an explicit
            transpose operation to X and W.
            X (IRNode): The X input tensor.
            W (IRNode): The W input tensor.
            Bias (IRNode): The bias tensor.
            Meta (IRNode): The meta tensor.
            Y (IRNode): The output tensor.
            alpha (float): Scaling factor for the product of the inputs.
            beta (float): Scaling factor for the output tensor.
            kernel (CUDATemplateKernel): CUDA Template kernel for the operation.
            epilogue_args (any): Additional arguments for the epilogue state.

        Returns:
            str: A block of CUDA C++ code as a string, ready to be used as arguments for the GEMM operation.

        Note: If `should_swap_xw` is True, a transpose operation will be applied to the X, W, Bias, and Y
        tensors. This operation also implies the M and N dimensions of Bias and GEMM output to be swapped
        before the function call.
        """
        ...
    



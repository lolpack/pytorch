"""
This type stub file was generated by pyright.
"""

import functools
from collections.abc import Sequence
from typing import Any, Optional, Union
from torch._inductor import config
from torch._inductor.cpu_vec_isa import VecISA

if config.is_fbcode():
    ...
else:
    def log_global_cache_errors(*args: Any, **kwargs: Any) -> None:
        ...
    
    def log_global_cache_stats(*args: Any, **kwargs: Any) -> None:
        ...
    
    def log_global_cache_vals(*args: Any, **kwargs: Any) -> None:
        ...
    
    def use_global_cache() -> bool:
        ...
    
_BUILD_TEMP_DIR = ...
_HERE = ...
_TORCH_PATH = ...
_LINKER_SCRIPT = ...
_IS_LINUX = ...
_IS_MACOS = ...
_IS_WINDOWS = ...
SUBPROCESS_DECODE_ARGS = ...
log = ...
@functools.lru_cache(1)
def cpp_compiler_search(search: str) -> str:
    ...

def install_gcc_via_conda() -> str:
    """On older systems, this is a quick way to get a modern compiler"""
    ...

@functools.cache
def check_compiler_exist_windows(compiler: str) -> None:
    """
    Check if compiler is ready, in case end user not activate MSVC environment.
    """
    ...

def get_cpp_compiler() -> str:
    ...

def get_ld_and_objcopy(use_relative_path: bool) -> tuple[str, str]:
    ...

def convert_cubin_to_obj(cubin_file: str, kernel_name: str, ld: str, objcopy: str) -> str:
    ...

@functools.cache
def is_gcc() -> bool:
    ...

@functools.cache
def is_clang() -> bool:
    ...

@functools.cache
def is_intel_compiler() -> bool:
    ...

@functools.cache
def is_apple_clang() -> bool:
    ...

@functools.cache
def is_msvc_cl() -> bool:
    ...

@functools.cache
def get_compiler_version_info(compiler: str) -> str:
    ...

def run_compile_cmd(cmd_line: str, cwd: str) -> None:
    ...

def normalize_path_separator(orig_path: str) -> str:
    ...

class BuildOptionsBase:
    """
    This is the Base class for store cxx build options, as a template.
    Actually, to build a cxx shared library. We just need to select a compiler
    and maintains the suitable args.
    """
    def __init__(self, compiler: str = ..., definitions: Optional[list[str]] = ..., include_dirs: Optional[list[str]] = ..., cflags: Optional[list[str]] = ..., ldflags: Optional[list[str]] = ..., libraries_dirs: Optional[list[str]] = ..., libraries: Optional[list[str]] = ..., passthrough_args: Optional[list[str]] = ..., aot_mode: bool = ..., use_relative_path: bool = ..., compile_only: bool = ..., precompiling: bool = ..., preprocessing: bool = ...) -> None:
        ...
    
    def get_compiler(self) -> str:
        ...
    
    def get_definitions(self) -> list[str]:
        ...
    
    def get_include_dirs(self) -> list[str]:
        ...
    
    def get_cflags(self) -> list[str]:
        ...
    
    def get_ldflags(self) -> list[str]:
        ...
    
    def get_libraries_dirs(self) -> list[str]:
        ...
    
    def get_libraries(self) -> list[str]:
        ...
    
    def get_passthrough_args(self) -> list[str]:
        ...
    
    def get_aot_mode(self) -> bool:
        ...
    
    def get_use_relative_path(self) -> bool:
        ...
    
    def get_compile_only(self) -> bool:
        ...
    
    def get_precompiling(self) -> bool:
        ...
    
    def get_preprocessing(self) -> bool:
        ...
    
    def save_flags_to_json(self, file: str) -> None:
        ...
    


def get_cpp_options(cpp_compiler: str, do_link: bool, warning_all: bool = ..., extra_flags: Sequence[str] = ..., min_optimize: bool = ...) -> tuple[list[str], list[str], list[str], list[str], list[str], list[str], list[str]]:
    ...

class CppOptions(BuildOptionsBase):
    """
    This class is inherited from BuildOptionsBase, and as cxx build options.
    This option need contains basic cxx build option, which contains:
    1. OS related args.
    2. Toolchains related args.
    3. Cxx standard related args.
    Note:
    1. This Options is good for assist modules build, such as x86_isa_help.
    """
    def __init__(self, compile_only: bool = ..., warning_all: bool = ..., extra_flags: Sequence[str] = ..., use_relative_path: bool = ..., compiler: str = ..., min_optimize: bool = ..., precompiling: bool = ..., preprocessing: bool = ...) -> None:
        ...
    


@functools.cache
def is_conda_llvm_openmp_installed() -> bool:
    ...

@functools.cache
def homebrew_libomp() -> tuple[bool, str]:
    ...

@functools.cache
def perload_clang_libomp_win(cpp_compiler: str, omp_name: str) -> None:
    ...

@functools.cache
def perload_icx_libomp_win(cpp_compiler: str) -> None:
    """
    Intel Compiler implemented more math libraries than clang, for performance proposal.
    We need preload them like openmp library.
    """
    ...

def get_mmap_self_macro(use_mmap_weights: bool) -> list[str]:
    ...

def get_cpp_torch_options(cpp_compiler: str, vec_isa: VecISA, include_pytorch: bool, aot_mode: bool, use_relative_path: bool, use_mmap_weights: bool) -> tuple[list[str], list[str], list[str], list[str], list[str], list[str], list[str]]:
    ...

class CppTorchOptions(CppOptions):
    """
    This class is inherited from CppTorchOptions, which automatic contains
    base cxx build options. And then it will maintains torch related build
    args.
    1. Torch include_directories, libraries, libraries_directories.
    2. Python include_directories, libraries, libraries_directories.
    3. OpenMP related.
    4. Torch MACROs.
    5. MISC
    """
    def __init__(self, vec_isa: VecISA = ..., include_pytorch: bool = ..., warning_all: bool = ..., aot_mode: bool = ..., compile_only: bool = ..., use_relative_path: bool = ..., use_mmap_weights: bool = ..., shared: bool = ..., extra_flags: Sequence[str] = ..., compiler: str = ..., min_optimize: bool = ..., precompiling: bool = ..., preprocessing: bool = ...) -> None:
        ...
    


def get_cpp_torch_device_options(device_type: str, aot_mode: bool = ..., compile_only: bool = ...) -> tuple[list[str], list[str], list[str], list[str], list[str], list[str], list[str]]:
    ...

class CppTorchDeviceOptions(CppTorchOptions):
    """
    This class is inherited from CppTorchOptions, which automatic contains
    base cxx build options and torch common build options. And then it will
    maintains cuda/xpu device related build args.
    """
    def __init__(self, vec_isa: VecISA = ..., include_pytorch: bool = ..., device_type: str = ..., aot_mode: bool = ..., compile_only: bool = ..., use_relative_path: bool = ..., use_mmap_weights: bool = ..., shared: bool = ..., extra_flags: Sequence[str] = ..., min_optimize: bool = ..., precompiling: bool = ..., preprocessing: bool = ...) -> None:
        ...
    


def get_name_and_dir_from_output_file_path(file_path: str) -> tuple[str, str]:
    """
    This function help prepare parameters to new cpp_builder.
    Example:
        input_code: /tmp/tmpof1n5g7t/5c/c5crkkcdvhdxpktrmjxbqkqyq5hmxpqsfza4pxcf3mwk42lphygc.cpp
        name, dir = get_name_and_dir_from_output_file_path(input_code)
    Run result:
        name = c5crkkcdvhdxpktrmjxbqkqyq5hmxpqsfza4pxcf3mwk42lphygc
        dir = /tmp/tmpof1n5g7t/5c/

    put 'name' and 'dir' to CppBuilder's 'name' and 'output_dir'.
    CppBuilder --> get_target_file_path will format output path according OS:
    Linux: /tmp/tmppu87g3mm/zh/czhwiz4z7ca7ep3qkxenxerfjxy42kehw6h5cjk6ven4qu4hql4i.so
    Windows: [Windows temp path]/tmppu87g3mm/zh/czhwiz4z7ca7ep3qkxenxerfjxy42kehw6h5cjk6ven4qu4hql4i.dll
    """
    ...

class CppBuilder:
    """
    CppBuilder is a cpp jit builder, and it supports both Windows, Linux and MacOS.
    Args:
        name:
            1. Build target name, the final target file will append extension type automatically.
            2. Due to the CppBuilder is supports multiple OS, it will maintains ext for OS difference.
        sources:
            Source code file list to be built.
        BuildOption:
            Build options to the builder.
        output_dir:
            1. The output_dir the target file will output to.
            2. The default value is empty string, and then the use current dir as output dir.
            3. Final target file: output_dir/name.ext
    """
    def __init__(self, name: str, sources: Union[str, list[str]], BuildOption: BuildOptionsBase, output_dir: str = ...) -> None:
        ...
    
    def get_command_line(self) -> str:
        ...
    
    def get_target_file_path(self) -> str:
        ...
    
    def build_fbcode_re(self) -> None:
        ...
    
    def build(self) -> None:
        """
        It is must need a temporary directory to store object files in Windows.
        After build completed, delete the temporary directory to save disk space.
        """
        ...
    
    def save_compile_cmd_to_cmake(self, cmake_path: str, device_type: str) -> None:
        """
        Save global cmake settings here, e.g. compiler options.
        If targeting CUDA, also emit a custom function to embed CUDA kernels.
        """
        ...
    
    def save_src_to_cmake(self, cmake_path: str, src_path: str) -> None:
        ...
    
    def save_kernel_asm_to_cmake(self, cmake_path: str, asm_files: list[str]) -> None:
        ...
    
    def save_link_cmd_to_cmake(self, cmake_path: str) -> None:
        ...
    



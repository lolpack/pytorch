"""
This type stub file was generated by pyright.
"""

import torch
from typing import Any, Optional

aten = ...
prims = ...
log = ...
def replace_params_with_constants(gm: torch.fx.GraphModule, flat_params: list[Any], fw_metadata: torch._functorch.aot_autograd.ViewAndMutationMeta) -> list[int]:
    """
    Replaces the parameters of a PyTorch GraphModule with constants wherever possible.
    Returns a list of indices representing the input parameters that were not converted to constants.
    """
    ...

def freeze(dynamo_gm: torch.fx.GraphModule, aot_autograd_gm: torch.fx.GraphModule, example_inputs: list[torch._subclasses.FakeTensor]) -> tuple[torch.fx.GraphModule, list[int]]:
    """
    Inlines parameters that are not mutated into constants and optimizes the graph through constant propagation
    and other techniques. If enabled, the function also discards the original parameters of the module for memory efficiency.

    Assumes that this function is run in dynamo tracing post aot_autograd.

    Args:
        dynamo_gm (torch.fx.GraphModule): The Dynamo constructed GraphModule.
        aot_autograd_gm (torch.fx.GraphModule): The aot_autograd constructed GraphModule to be frozen.
        example_inputs (List[torch.Tensor]): A list of example input tensors to be used in the freezing process.

    Returns:
        Tuple[torch.fx.GraphModule, List[int]]: A tuple containing the frozen GraphModule and a list of indices
        of the inputs that were preserved (not turned into constants).
    """
    ...

class ErasedTensor(torch.Tensor):
    @staticmethod
    def __new__(cls, elem, name, owning_mod):
        ...
    
    def __init__(self, elem, name: Optional[str], mod) -> None:
        ...
    
    @classmethod
    def __torch_dispatch__(cls, func, types, args=..., kwargs=...):
        ...
    


def invalidate_eager_modules(): # -> None:
    ...

def discard_traced_gm_params(mod: torch.fx.GraphModule): # -> None:
    ...

def enforce_output_layout(gm: torch.fx.GraphModule): # -> None:
    """
    Make sure the output node's layout does not change due to compiler optimizations
    by adding aten.as_strided nodes with the expected strides.

    Only used for inference so we can assume all graph outputs are model outputs.
    """
    ...

def enforce_as_strided_input_layout(gm: torch.fx.GraphModule): # -> None:
    """
    Make sure the as_strided node's input's layout does not change due to compiler
    optimizations, because the as_strided strides info depends on input tensor stride info.
    """
    ...

def convert_conv_weights_to_channels_last(gm: torch.fx.GraphModule): # -> None:
    """
    Convert 4d convolution weight tensor to channels last format.

    This pass is performed before freezing so the added nodes can be constant
    folded by freezing.
    """
    ...


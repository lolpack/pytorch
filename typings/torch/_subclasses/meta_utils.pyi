"""
This type stub file was generated by pyright.
"""

import torch
from abc import abstractmethod
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Callable, ClassVar, Generic, NewType, Optional, Protocol, TYPE_CHECKING, TypeVar, Union
from typing_extensions import TypeGuard, TypedDict, Unpack, override
from torch._C._autograd import CreationMeta
from torch._C._functorch import CInterpreter, is_batchedtensor, is_gradtrackingtensor, is_legacy_batchedtensor
from torch.utils._python_dispatch import is_traceable_wrapper_subclass
from collections.abc import Generator
from torch._guards import Source
from torch._subclasses.fake_tensor import FakeTensor, FakeTensorMode
from torch.fx.experimental.symbolic_shapes import ShapeEnv, SymbolicContext

if TYPE_CHECKING:
    ...
DimList = list
_TensorLikeT = TypeVar("_TensorLikeT", "MetaTensorDesc", torch.Tensor)
_T = TypeVar("_T")
_TensorT = TypeVar("_TensorT", bound=torch.Tensor)
_TensorT_cov = TypeVar("_TensorT_cov", bound=torch.Tensor, covariant=True)
def safe_is_leaf(t: Union[MetaTensorDesc, torch.Tensor]) -> bool:
    ...

def safe_grad(t: _TensorLikeT) -> Optional[_TensorLikeT]:
    ...

def assert_eq(a: _T, b: _T) -> None:
    ...

tls = ...
@contextmanager
def disable_inference_mode_for_fake_prop() -> Generator[None, None, None]:
    ...

def assert_metadata_eq(assert_eq: Callable[[object, object], None], m1: Union[MetaTensorDesc, torch.Tensor], m2: torch.Tensor, *, skip_symbolic: bool = ..., skip_leaf: bool = ...) -> None:
    ...

def is_sparse_coo(t: object) -> TypeGuard[torch.Tensor]:
    ...

def is_sparse_compressed_layout(layout: torch.layout) -> bool:
    ...

def is_sparse_compressed(t: object) -> TypeGuard[torch.Tensor]:
    ...

def is_sparse_any(t: object) -> TypeGuard[torch.Tensor]:
    ...

MetaStorageId = NewType("MetaStorageId", int)
MetaTensorId = NewType("MetaTensorId", int)
_DescriberId = NewType("_DescriberId", int)
DESCRIBER_NEXT_ID = ...
class MetaTensorDescriber:
    """
    Given a Tensor/Storage, generate a MetaTensorDesc/MetaStorageDesc
    for it, which is enough information to reconstruct a meta tensor/fake tensor
    corresponding to a Tensor as faithfully as possible.

    This is a stateful conversion object because we keep track of the IDs
    of the tensors/storages passed to us, so we can consistently give
    the same ID when we see the same tensor/storage.
    """
    def __init__(self, *, copy_data: bool = ...) -> None:
        ...
    
    def get_tensor_id(self, t: torch.Tensor) -> MetaTensorId:
        ...
    
    def get_storage_id(self, s: torch.UntypedStorage) -> MetaStorageId:
        ...
    
    def describe_storage(self, s: torch.UntypedStorage, *, trace: bool = ...) -> MetaStorageDesc:
        ...
    
    def describe_tensor(self, t: torch.Tensor, *, recurse: bool = ..., trace: bool = ...) -> MetaTensorDesc:
        ...
    


@dataclass(frozen=True)
class MetaStorageDesc:
    id: MetaStorageId
    size: int
    data: Optional[torch.UntypedStorage]
    def as_json(self, describer_id: _DescriberId) -> dict[str, object]:
        ...
    


@dataclass(frozen=True)
class ViewFunc(Generic[_TensorT]):
    @abstractmethod
    def apply(self, t: _TensorT, new_base: _TensorT, symint_visitor_fn: Optional[Callable[[int], int]] = ..., tensor_visitor_fn: Optional[Callable[[torch.Tensor], _TensorT]] = ...) -> _TensorT:
        ...
    
    @staticmethod
    def from_tensor(t: torch.Tensor) -> ViewFunc:
        ...
    


@dataclass(frozen=True)
class _FakeTensorViewFunc(ViewFunc["FakeTensor"]):
    @override
    def apply(self, t: torch.Tensor, new_base: torch.Tensor, symint_visitor_fn: Optional[Callable[[int], int]] = ..., tensor_visitor_fn: Optional[Callable[[torch.Tensor], FakeTensor]] = ...) -> FakeTensor:
        ...
    


@dataclass(frozen=True)
class _CustomViewFunc(ViewFunc[_TensorT], Generic[_TensorT]):
    func: Callable[[torch.Tensor, Optional[Callable[[int], int]], Optional[Callable[[torch.Tensor], _TensorT]]], _TensorT,]
    @override
    def apply(self, t: torch.Tensor, new_base: torch.Tensor, symint_visitor_fn: Optional[Callable[[int], int]] = ..., tensor_visitor_fn: Optional[Callable[[torch.Tensor], _TensorT]] = ...) -> _TensorT:
        ...
    


class _MetaTensorCallback(Protocol, Generic[_TensorT_cov]):
    def __call__(self, arg: Callable[[], torch.Tensor], /, *, device: Union[torch.device, str]) -> _TensorT_cov:
        ...
    


class _MetaTensorCallbackKwargs(TypedDict, total=False):
    device: Union[torch.device, str]
    ...


class _MetaTensorCallbackOptDevice(Protocol, Generic[_TensorT_cov]):
    def __call__(self, arg: Callable[[], torch.Tensor], /, **kwargs: Unpack[_MetaTensorCallbackKwargs]) -> _TensorT_cov:
        ...
    


@dataclass(frozen=True)
class MetaTensorDesc(Generic[_TensorT]):
    id: MetaTensorId
    ndim: int
    dtype: torch.dtype
    device: torch.device
    size: tuple[int, ...]
    dynamo_dynamic_indices: list[int]
    layout: torch.layout = ...
    is_inference: bool = ...
    is_leaf: bool = ...
    requires_grad: bool = ...
    is_sparse: bool = ...
    is_mkldnn: bool = ...
    is_functorch_wrapped: bool = ...
    is_batchedtensor: bool = ...
    is_legacy_batchedtensor: bool = ...
    is_gradtrackingtensor: bool = ...
    is_view: bool = ...
    is_nested: bool = ...
    nested_int: Optional[int] = ...
    is_traceable_wrapper_subclass: bool = ...
    is_functional: bool = ...
    is_conj: bool = ...
    is_neg: bool = ...
    is_parameter: bool = ...
    stride: Optional[tuple[int, ...]] = ...
    storage_offset: int = ...
    storage: Optional[MetaStorageDesc] = ...
    sparse_dim: Optional[int] = ...
    dense_dim: Optional[int] = ...
    is_coalesced: Optional[bool] = ...
    crow_indices: Optional[MetaTensorDesc] = ...
    col_indices: Optional[MetaTensorDesc] = ...
    ccol_indices: Optional[MetaTensorDesc] = ...
    row_indices: Optional[MetaTensorDesc] = ...
    values: Optional[MetaTensorDesc] = ...
    unwrapped: Optional[MetaTensorDesc] = ...
    bdim: Optional[int] = ...
    base: Optional[MetaTensorDesc] = ...
    attrs: Optional[dict[str, MetaTensorDesc]] = ...
    creation_meta: Optional[CreationMeta] = ...
    grad: Optional[MetaTensorDesc] = ...
    _UNSERIALIZABLE: ClassVar[set[str]] = ...
    ctx: Optional[object] = ...
    type: Optional[type] = ...
    fake_mode: Optional[FakeTensorMode] = ...
    view_func: Optional[ViewFunc] = ...
    level: Optional[int] = ...
    current_level: Optional[int] = ...
    functorch_stack: Optional[list[CInterpreter]] = ...
    autograd_meta_from: Optional[torch.Tensor] = ...
    data: Optional[torch.Tensor] = ...
    def as_json(self, describer_id: _DescriberId) -> dict[str, object]:
        ...
    
    @property
    def shape(self) -> tuple[int, ...]:
        ...
    


class MetaConverter(Generic[_TensorT]):
    def __init__(self, *, copy_data: bool = ...) -> None:
        ...
    
    def successful(self) -> bool:
        ...
    
    def get_tensor_memo(self, t: MetaTensorDesc) -> Optional[torch.Tensor]:
        ...
    
    def set_tensor_memo(self, t: MetaTensorDesc, v: _TensorT) -> None:
        ...
    
    def get_storage_memo(self, s: MetaStorageDesc) -> Optional[torch.UntypedStorage]:
        ...
    
    def set_storage_memo(self, s: MetaStorageDesc, v: torch.UntypedStorage) -> None:
        ...
    
    def meta_storage(self, s: MetaStorageDesc, callback: Callable[[Callable[[], torch.Tensor]], _TensorT]) -> torch.UntypedStorage:
        ...
    
    def meta_tensor(self, t: MetaTensorDesc, shape_env: Optional[ShapeEnv], callback_: _MetaTensorCallback[_TensorT], source: Optional[Source], symbolic_context: Optional[SymbolicContext]) -> _TensorT:
        ...
    
    def __call__(self, t: torch.Tensor, shape_env: Optional[ShapeEnv] = ..., *, callback: Optional[_MetaTensorCallback[_TensorT]] = ..., source: Optional[Source] = ..., symbolic_context: Optional[SymbolicContext] = ..., trace: bool = ...) -> _TensorT:
        ...
    



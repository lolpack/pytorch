"""
This type stub file was generated by pyright.
"""

import contextlib
import functools
import io
import os
import platform
import subprocess
import sys
import unittest
import expecttest
import torch
from collections.abc import Iterable, Iterator
from contextlib import contextmanager
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import Any, Callable, Optional, TypeVar, Union
from torch.testing._comparison import BooleanPair, NumberPair, Pair, TensorLikePair

r"""Importing this file must **not** initialize CUDA context. test_distributed
relies on this assumption to properly run. This means that when this is imported
no CUDA calls shall be made, including torch.cuda.device_count(), etc.

torch.testing._internal.common_cuda.py can freely initialize CUDA context when imported.
"""
has_pytest = ...
MI300_ARCH = ...
def freeze_rng_state(*args, **kwargs): # -> _GeneratorContextManager[None, None, None]:
    ...

class TestEnvironment:
    repro_env_vars: dict = ...
    @staticmethod
    def def_flag(name, env_var=..., default=..., include_in_repro=..., enabled_fn=..., implied_by_fn=...): # -> Literal[True]:
        ...
    
    @staticmethod
    def def_setting(name, env_var=..., default=..., include_in_repro=..., parse_fn=...):
        ...
    
    @staticmethod
    def repro_env_var_prefix() -> str:
        ...
    


log = ...
FILE_SCHEMA = ...
if sys.platform == 'win32':
    ...
IS_CI: bool = ...
IS_SANDCASTLE: bool = ...
IN_RE_WORKER: bool = ...
_is_fbcode_default = ...
IS_FBCODE: bool = ...
IS_REMOTE_GPU: bool = ...
DISABLE_RUNNING_SCRIPT_CHK: bool = ...
PRINT_REPRO_ON_FAILURE: bool = ...
OPINFO_SAMPLE_INPUT_INDEX: Optional[int] = ...
DEFAULT_DISABLED_TESTS_FILE = ...
DEFAULT_SLOW_TESTS_FILE = ...
disabled_tests_dict = ...
slow_tests_dict = ...
def maybe_load_json(filename): # -> Any | dict[Any, Any]:
    ...

if os.getenv("SLOW_TESTS_FILE", ""):
    slow_tests_dict = ...
if os.getenv("DISABLED_TESTS_FILE", ""):
    disabled_tests_dict = ...
NATIVE_DEVICES = ...
DEVICE_LIST_SUPPORT_PROFILING_TEST = ...
ALLOW_XPU_PROFILING_TEST = ...
check_names = ...
IS_JETSON = ...
def gcIfJetson(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def extract_test_fn() -> Optional[Callable]:
    ...

@dataclass
class TrackedInput:
    index: int
    val: Any
    type_desc: str
    ...


def get_tracked_input() -> Optional[TrackedInput]:
    ...

def clear_tracked_input() -> None:
    ...

class TrackedInputIter:
    def __init__(self, child_iter, input_type_desc, item_callback=..., track_callback=..., set_seed=..., restrict_to_index=...) -> None:
        ...
    
    def __iter__(self): # -> Self:
        ...
    
    def __next__(self):
        ...
    


class _TestParametrizer:
    """
    Decorator class for parametrizing a test function, yielding a set of new tests spawned
    from the original generic test, each specialized for a specific set of test inputs. For
    example, parametrizing a test across the set of ops will result in a test function per op.

    The decision of how to parametrize / what to parametrize over is intended to be implemented
    by each derived class.

    In the details, the decorator adds a 'parametrize_fn' property to the test function. This function
    is intended to be called later by one of:
      * Device-specific test instantiation via instantiate_device_type_tests(). Note that for this
        case there is no need to explicitly parametrize over device type, as that is handled separately.
      * Device-agnostic parametrized test instantiation via instantiate_parametrized_tests().

    If the decorator is applied to a test function that already has a 'parametrize_fn' property, a new
    composite 'parametrize_fn' will be created that generates tests with the product of the parameters
    generated by the old and new parametrize_fns. This allows for convenient composability of decorators.
    """
    def __call__(self, fn):
        ...
    


def compose_parametrize_fns(old_parametrize_fn, new_parametrize_fn): # -> Callable[..., Generator[tuple[Any, str, dict[Any, Any], Callable[..., list[Any]]], Any, None]]:
    """
    Returns a parametrize_fn that parametrizes over the product of the parameters handled
    by the given parametrize_fns. Each given parametrize_fn should each have the signature
    f(test, generic_cls, device_cls).

    The test names will be a combination of the names produced by the parametrize_fns in
    "<new_name>_<old_name>" order. This order is done to match intuition for constructed names
    when composing multiple decorators; the names will be built in top to bottom order when stacking
    parametrization decorators.

    Args:
        old_parametrize_fn (callable) - First parametrize_fn to compose.
        new_parametrize_fn (callable) - Second parametrize_fn to compose.
    """
    ...

def instantiate_parametrized_tests(generic_cls):
    """
    Instantiates tests that have been decorated with a parametrize_fn. This is generally performed by a
    decorator subclass of _TestParametrizer. The generic test will be replaced on the test class by
    parametrized tests with specialized names. This should be used instead of
    instantiate_device_type_tests() if the test class contains device-agnostic tests.

    You can also use it as a class decorator. E.g.

    ```
    @instantiate_parametrized_tests
    class TestFoo(TestCase):
        ...
    ```

    Args:
        generic_cls (class): Generic test class object containing tests (e.g. TestFoo)
    """
    ...

class subtest:
    """
    Explicit subtest case for use with test parametrization.
    Allows for explicit naming of individual subtest cases as well as applying
    decorators to the parametrized test.

    Args:
        arg_values (iterable): Iterable of arg values (e.g. range(10)) or
            tuples of arg values (e.g. [(1, 2), (3, 4)]).
        name (str): Optional name to use for the test.
        decorators (iterable): Iterable of decorators to apply to the generated test.
    """
    __slots__ = ...
    def __init__(self, arg_values, name=..., decorators=...) -> None:
        ...
    


class parametrize(_TestParametrizer):
    """
    Decorator for applying generic test parametrizations.

    The interface for this decorator is modeled after `@pytest.mark.parametrize`.
    Basic usage between this decorator and pytest's is identical. The first argument
    should be a string containing comma-separated names of parameters for the test, and
    the second argument should be an iterable returning values or tuples of values for
    the case of multiple parameters.

    Beyond this basic usage, the decorator provides some additional functionality that
    pytest does not.

    1. Parametrized tests end up as generated test functions on unittest test classes.
    Since this differs from how pytest works, this decorator takes on the additional
    responsibility of naming these test functions. The default test names consists of
    the test's base name followed by each parameter name + value (e.g. "test_bar_x_1_y_foo"),
    but custom names can be defined using `name_fn` or the `subtest` structure (see below).

    2. The decorator specially handles parameter values of type `subtest`, which allows for
    more fine-grained control over both test naming and test execution. In particular, it can
    be used to tag subtests with explicit test names or apply arbitrary decorators (see examples
    below).

    Examples::

        @parametrize("x", range(5))
        def test_foo(self, x):
            ...

        @parametrize("x,y", [(1, 'foo'), (2, 'bar'), (3, 'baz')])
        def test_bar(self, x, y):
            ...

        @parametrize("x,y", [(1, 'foo'), (2, 'bar'), (3, 'baz')],
                     name_fn=lambda x, y: '{}_{}'.format(x, y))
        def test_bar_custom_names(self, x, y):
            ...

        @parametrize("x, y", [subtest((1, 2), name='double'),
                              subtest((1, 3), name='triple', decorators=[unittest.expectedFailure]),
                              subtest((1, 4), name='quadruple')])
        def test_baz(self, x, y):
            ...

    To actually instantiate the parametrized tests, one of instantiate_parametrized_tests() or
    instantiate_device_type_tests() should be called. The former is intended for test classes
    that contain device-agnostic tests, while the latter should be used for test classes that
    contain device-specific tests. Both support arbitrary parametrizations using the decorator.

    Args:
        arg_str (str): String of arg names separate by commas (e.g. "x,y").
        arg_values (iterable): Iterable of arg values (e.g. range(10)) or
            tuples of arg values (e.g. [(1, 2), (3, 4)]).
        name_fn (Callable): Optional function that takes in parameters and returns subtest name.
    """
    def __init__(self, arg_str, arg_values, name_fn=...) -> None:
        ...
    


class reparametrize(_TestParametrizer):
    """
    Decorator for adjusting the way an existing parametrizer operates. This class runs
    the given adapter_fn on each parametrization produced by the given parametrizer,
    allowing for on-the-fly parametrization more flexible than the default,
    product-based composition that occurs when stacking parametrization decorators.

    If the adapter_fn returns None for a given test parametrization, that parametrization
    will be excluded. Otherwise, it's expected that the adapter_fn returns an iterable of
    modified parametrizations, with tweaked test names and parameter kwargs.

    Examples::

        def include_is_even_arg(test_name, param_kwargs):
            x = param_kwargs["x"]
            is_even = x % 2 == 0
            new_param_kwargs = dict(param_kwargs)
            new_param_kwargs["is_even"] = is_even
            is_even_suffix = "_even" if is_even else "_odd"
            new_test_name = f"{test_name}{is_even_suffix}"
            yield (new_test_name, new_param_kwargs)

        ...

        @reparametrize(parametrize("x", range(5)), include_is_even_arg)
        def test_foo(self, x, is_even):
            ...

        def exclude_odds(test_name, param_kwargs):
            x = param_kwargs["x"]
            is_even = x % 2 == 0
            yield None if not is_even else (test_name, param_kwargs)

        ...

        @reparametrize(parametrize("x", range(5)), exclude_odds)
        def test_bar(self, x):
            ...

    """
    def __init__(self, parametrizer, adapter_fn) -> None:
        ...
    


class decorateIf(_TestParametrizer):
    """
    Decorator for applying parameter-specific conditional decoration.
    Composes with other test parametrizers (e.g. @modules, @ops, @parametrize, etc.).

    Examples::

        @decorateIf(unittest.skip, lambda params: params["x"] == 2)
        @parametrize("x", range(5))
        def test_foo(self, x):
            ...

        @parametrize("x,y", [(1, 'foo'), (2, 'bar'), (3, 'baz')])
        @decorateIf(
            unittest.expectedFailure,
            lambda params: params["x"] == 3 and params["y"] == "baz"
        )
        def test_bar(self, x, y):
            ...

        @decorateIf(
            unittest.expectedFailure,
            lambda params: params["op"].name == "add" and params["dtype"] == torch.float16
        )
        @ops(op_db)
        def test_op_foo(self, device, dtype, op):
            ...

        @decorateIf(
            unittest.skip,
            lambda params: params["module_info"].module_cls is torch.nn.Linear and \
                params["device"] == "cpu"
        )
        @modules(module_db)
        def test_module_foo(self, device, dtype, module_info):
            ...

    Args:
        decorator: Test decorator to apply if the predicate is satisfied.
        predicate_fn (Callable): Function taking in a dict of params and returning a boolean
            indicating whether the decorator should be applied or not.
    """
    def __init__(self, decorator, predicate_fn) -> None:
        ...
    


class ProfilingMode(Enum):
    LEGACY = ...
    SIMPLE = ...
    PROFILING = ...


def cppProfilingFlagsToProfilingMode(): # -> Literal[ProfilingMode.PROFILING, ProfilingMode.SIMPLE, ProfilingMode.LEGACY]:
    ...

@contextmanager
def enable_profiling_mode_for_profiling_tests(): # -> Generator[None, Any, None]:
    ...

@contextmanager
def enable_profiling_mode(): # -> Generator[None, Any, None]:
    ...

@contextmanager
def num_profiled_runs(num_runs): # -> Generator[None, Any, None]:
    ...

func_call = ...
meth_call = ...
def prof_callable(callable, *args, **kwargs):
    ...

def raise_on_run_directly(file_to_call):
    ...

def prof_func_call(*args, **kwargs):
    ...

def prof_meth_call(*args, **kwargs):
    ...

is_running_via_run_test = ...
parser = ...
def run_unittest_help(argv): # -> None:
    ...

if '-h' in sys.argv or '--help' in sys.argv:
    help_thread = ...
if args.jit_executor == 'legacy':
    GRAPH_EXECUTOR = ...
else:
    GRAPH_EXECUTOR = ...
RERUN_DISABLED_TESTS = args.rerun_disabled_tests
SLOW_TESTS_FILE = args.import_slow_tests
DISABLED_TESTS_FILE = args.import_disabled_tests
LOG_SUFFIX = args.log_suffix
RUN_PARALLEL = args.run_parallel
TEST_BAILOUTS = args.test_bailouts
USE_PYTEST = args.use_pytest
PYTEST_SINGLE_TEST = args.pytest_single_test
TEST_DISCOVER = args.discover_tests
TEST_IN_SUBPROCESS = args.subprocess
TEST_SAVE_XML = args.save_xml
REPEAT_COUNT = args.repeat
SEED = args.seed
SHOWLOCALS = args.showlocals
if not getattr(expecttest, "ACCEPT", False):
    ...
UNITTEST_ARGS = ...
CI_TEST_PREFIX = ...
CI_PT_ROOT = ...
CI_FUNCTORCH_ROOT = ...
def wait_for_process(p, timeout=...):
    ...

def shell(command, cwd=..., env=..., stdout=..., stderr=..., timeout=...): # -> int:
    ...

def retry_shell(command, cwd=..., env=..., stdout=..., stderr=..., timeout=..., retries=..., was_rerun=...) -> tuple[int, bool]:
    ...

def discover_test_cases_recursively(suite_or_case): # -> list[TestCase] | list[Any]:
    ...

def get_test_names(test_cases): # -> list[str]:
    ...

def chunk_list(lst, nchunks): # -> list[Any]:
    ...

def sanitize_test_filename(filename): # -> str:
    ...

def lint_test_case_extension(suite): # -> bool:
    ...

def get_report_path(argv=..., pytest=...): # -> str:
    ...

def sanitize_pytest_xml(xml_file: str): # -> None:
    ...

def get_pytest_test_cases(argv: list[str]) -> list[str]:
    class TestCollectorPlugin:
        ...
    
    

def run_tests(argv=...): # -> None:
    ...

IS_LINUX = ...
IS_WINDOWS = ...
IS_MACOS = ...
IS_PPC = ...
IS_X86 = ...
IS_ARM64 = ...
IS_S390X = ...
def is_avx512_vnni_supported(): # -> Literal[False]:
    ...

IS_AVX512_VNNI_SUPPORTED = ...
if IS_WINDOWS:
    @contextmanager
    def TemporaryFileName(*args, **kwargs): # -> Generator[Any, Any, None]:
        ...
    
else:
    @contextmanager
    def TemporaryFileName(*args, **kwargs): # -> Generator[Any, Any, None]:
        ...
    
if IS_WINDOWS:
    @contextmanager
    def TemporaryDirectoryName(suffix=...): # -> Generator[str, Any, None]:
        ...
    
else:
    @contextmanager
    def TemporaryDirectoryName(suffix=...): # -> Generator[str, Any, None]:
        ...
    
def is_privateuse1_backend_available(): # -> Any | None:
    ...

IS_FILESYSTEM_UTF8_ENCODING = ...
TEST_NUMPY = ...
TEST_FAIRSEQ = ...
TEST_SCIPY = ...
TEST_MKL = ...
TEST_ACL = ...
TEST_MPS = ...
MACOS_VERSION = ...
TEST_XPU = ...
TEST_HPU = ...
TEST_CUDA = ...
custom_device_mod = ...
TEST_PRIVATEUSE1 = ...
TEST_PRIVATEUSE1_DEVICE_TYPE = ...
TEST_NUMBA = ...
TEST_TRANSFORMERS = ...
TEST_DILL = ...
TEST_LIBROSA = ...
TEST_OPT_EINSUM = ...
TEST_Z3 = ...
def split_if_not_empty(x: str): # -> list[str]:
    ...

NOTEST_CPU = ...
skipIfNoDill = ...
NO_MULTIPROCESSING_SPAWN: bool = ...
TEST_WITH_ASAN: bool = ...
TEST_WITH_DEV_DBG_ASAN: bool = ...
TEST_WITH_TSAN: bool = ...
TEST_WITH_UBSAN: bool = ...
TEST_WITH_ROCM: bool = ...
TEST_WITH_MIOPEN_SUGGEST_NHWC = ...
TEST_WITH_SLOW: bool = ...
TEST_SKIP_FAST: bool = ...
TEST_WITH_CROSSREF: bool = ...
TEST_SKIP_CUDAGRAPH: bool = ...
TEST_CUDA_GRAPH = ...
TEST_CUDA_CUDSS = ...
TEST_CUDA_PYTHON_BINDINGS = ...
if TEST_CUDA_PYTHON_BINDINGS:
    def cuda_python_error_check(function_call_output): # -> tuple[Any, ...]:
        """Makes calls to cuda-python's cuda runtime functions more
        pythonic by throwing an exception if they return a status
        which is not cudaSuccess
        """
        ...
    
else:
    cuda_python_error_check = ...
def allocator_option_enabled_fn(allocator_config, _, option): # -> bool:
    ...

EXPANDABLE_SEGMENTS: bool = ...
if TEST_CUDA and 'NUM_PARALLEL_PROCS' in os.environ:
    num_procs = ...
    gb_available = ...
requires_cuda = ...
def skipIfCrossRef(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

class CrossRefMode(torch.overrides.TorchFunctionMode):
    def __torch_function__(self, func, types, args=..., kwargs=...):
        ...
    


TEST_WITH_TORCHINDUCTOR: bool = ...
TEST_WITH_AOT_EAGER: bool = ...
TEST_WITH_TORCHDYNAMO: bool = ...
TEST_WITHOUT_COMPILED_AUTOGRAD: bool = ...
if TEST_WITH_TORCHDYNAMO:
    ...
def xpassIfTorchDynamo_np(func):
    ...

def xfailIfACL(func):
    ...

def xfailIfTorchDynamo(func):
    ...

def xfailIfPy312Plus(func):
    ...

def xfailIfLinux(func):
    ...

def skipIfTorchDynamo(msg=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None] | type]:
    """
    Usage:
    @skipIfTorchDynamo(msg)
    def test_blah(self):
        ...
    """
    ...

def skipIfTorchInductor(msg=..., condition=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None] | type]:
    ...

def runWithoutCompiledAutograd(msg=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]]:
    """
    Usage:
    @runWithoutCompiledAutograd(msg)
    def test_blah(self):
        ...
    """
    ...

def serialTest(condition=...): # -> Callable[..., Any]:
    """
    Decorator for running tests serially.  Requires pytest
    """
    ...

def unMarkDynamoStrictTest(cls=...): # -> Callable[..., Any]:
    ...

def markDynamoStrictTest(cls_or_func=..., nopython=...): # -> Callable[..., type[Any] | _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]] | type[Any] | _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    """
    Marks the test as 'strict'. In strict mode, we reset before and after the
    test, and run without suppress errors.

    Args:
    - nopython: if we should run torch._dynamo.optimize with nopython={True/False}.
    """
    ...

def skipRocmIfTorchInductor(msg=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None] | type]:
    ...

def skipIfLegacyJitExecutor(msg=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None] | type]:
    ...

def make_dynamo_test(fn: Optional[Callable[..., Any]] = ...) -> Callable[..., Any]:
    """
    Decorator function to create a dynamo test case. A function annotate with
    this decorator takes as input a unittest object.
    """
    ...

TEST_WITH_TV = ...
if TEST_WITH_TV:
    ...
TEST_CUDA_MEM_LEAK_CHECK: bool = ...
numpy_to_torch_dtype_dict = ...
def numpy_to_torch_dtype(np_dtype):
    ...

def has_corresponding_torch_dtype(np_dtype): # -> bool:
    ...

if IS_WINDOWS:
    ...
torch_to_numpy_dtype_dict = ...
def skipIfNNModuleInlined(msg=..., condition=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None] | type]:
    ...

def skipIfRocm(func=..., *, msg=...): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any] | Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipIfRocmArch(arch: tuple[str, ...]): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def runOnRocm(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def runOnRocmArch(arch: tuple[str, ...]): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def xfailIfS390X(func):
    ...

def skipIfXpu(func=..., *, msg=...): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any] | Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipIfMPS(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skipIfMPSOnMacOS13(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skipIfHpu(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skipIfRocmVersionLessThan(version=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipIfNotMiopenSuggestNHWC(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skipIfWindows(func=..., *, msg=...): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any] | Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def requires_cuda_p2p_access(): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None] | Any]:
    ...

def setLinalgBackendsToDefaultFinally(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def setBlasBackendsToDefaultFinally(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

class DeterministicGuard:
    def __init__(self, deterministic, *, warn_only=..., fill_uninitialized_memory=...) -> None:
        ...
    
    def __enter__(self): # -> None:
        ...
    
    def __exit__(self, exception_type, exception_value, traceback): # -> None:
        ...
    


class AlwaysWarnTypedStorageRemoval:
    def __init__(self, always_warn) -> None:
        ...
    
    def __enter__(self): # -> None:
        ...
    
    def __exit__(self, exception_type, exception_value, traceback): # -> None:
        ...
    


class CudaSyncGuard:
    def __init__(self, sync_debug_mode) -> None:
        ...
    
    def __enter__(self): # -> None:
        ...
    
    def __exit__(self, exception_type, exception_value, traceback): # -> None:
        ...
    


class SwapTensorsGuard:
    def __init__(self, use_swap_tensors) -> None:
        ...
    
    def __enter__(self): # -> None:
        ...
    
    def __exit__(self, exception_type, exception_value, traceback): # -> None:
        ...
    


def wrapDeterministicFlagAPITest(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def wrapSwapTensorsTest(swap=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]]:
    ...

class swap(_TestParametrizer):
    def __init__(self, swap_values) -> None:
        ...
    


def skipIfCompiledWithoutNumpy(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skipIfNoXNNPACK(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skipIfNoLapack(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skipIfNotRegistered(op_name, message): # -> Callable[[_FT], _FT]:
    """Wraps the decorator to hide the import of the `core`.

    Args:
        op_name: Check if this op is registered in `core._REGISTERED_OPERATORS`.
        message: message to fail with.

    Usage:
        @skipIfNotRegistered('MyOp', 'MyOp is not linked!')
            This will check if 'MyOp' is in the caffe2.python.core
    """
    ...

def skipIfNoSciPy(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def skip_if_pytest(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipIfNoXPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def slowTest(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def slowTestIf(condition): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]] | Callable[..., Any]:
    ...

def skipCUDAMemoryLeakCheckIf(condition): # -> Callable[..., Any]:
    ...

def skipCUDANonDefaultStreamIf(condition): # -> Callable[..., Any]:
    ...

def suppress_warnings(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def to_gpu(obj, type_map=...): # -> list[Any | list[Any] | tuple[Any | list[Any] | tuple[Any, ...], ...]] | tuple[Any, ...]:
    ...

def get_function_arglist(func): # -> list[str]:
    ...

def set_rng_seed(seed): # -> None:
    ...

@contextlib.contextmanager
def set_default_dtype(dtype): # -> Generator[None, Any, None]:
    ...

@contextlib.contextmanager
def set_default_tensor_type(tensor_type): # -> Generator[None, Any, None]:
    ...

def iter_indices(tensor): # -> range | product[tuple[int, ...]]:
    ...

def is_iterable(obj): # -> bool:
    ...

def is_iterable_of_tensors(iterable, include_empty=...): # -> bool:
    """ Returns True if iterable is an iterable of tensors and False o.w.

        If the iterable is empty, the return value is :attr:`include_empty`
    """
    ...

class CudaNonDefaultStream:
    def __enter__(self): # -> None:
        ...
    
    def __exit__(self, exc_type, exc_value, traceback): # -> None:
        ...
    


class CudaMemoryLeakCheck:
    def __init__(self, testcase, name=...) -> None:
        ...
    
    def __enter__(self): # -> None:
        ...
    
    def __exit__(self, exc_type, exc_value, traceback): # -> None:
        ...
    


@contextmanager
def skip_exception_type(exc_type): # -> Generator[None, Any, None]:
    ...

@contextmanager
def print_repro_on_failure(repro_parts): # -> Generator[None, Any, None]:
    ...

def settings(*args, **kwargs):
    ...

def remove_device_and_dtype_suffixes(test_name: str) -> str:
    ...

def check_if_enable(test: unittest.TestCase): # -> None:
    ...

class RelaxedBooleanPair(BooleanPair):
    """Pair for boolean-like inputs.

    In contrast to the builtin :class:`BooleanPair`, this class also supports one input being a number or a single
    element tensor-like.
    """
    _supported_number_types = ...


class RelaxedNumberPair(NumberPair):
    """Pair for number-like inputs.

    In contrast to the builtin :class:`NumberPair`, this class also supports one input being a single element
    tensor-like or a :class:`enum.Enum`. (D)Type checks are disabled, meaning comparing 1 to 1.0 succeeds even when
    ``check_dtype=True`` is passed.

    In addition, this class uses looser default tolerances for :class:`float` and :class:`complex` inputs. Also
    supports overriding the absolute and relative tolerance through the ``@precisionOverride`` and
    ``@toleranceOverride`` decorators.
    """
    _TYPE_TO_DTYPE = ...
    def __init__(self, actual, expected, *, rtol_override=..., atol_override=..., check_dtype=..., **other_parameters) -> None:
        ...
    


class TensorOrArrayPair(TensorLikePair):
    """Pair for tensor-like inputs.

    On the one hand this class is stricter than the builtin :class:`TensorLikePair` since it only allows instances of
    :class:`torch.Tensor` and :class:`numpy.ndarray` rather than allowing any tensor-like than can be converted into a
    tensor. On the other hand this class is looser since it converts all inputs into tensors with no regard of their
    relationship, e.g. comparing a :class:`torch.Tensor` to :class:`numpy.ndarray` is fine.

    In addition, this class supports overriding the absolute and relative tolerance through the ``@precisionOverride``
    and ``@toleranceOverride`` decorators.
    """
    def __init__(self, actual, expected, *, rtol_override=..., atol_override=..., **other_parameters) -> None:
        ...
    


class TypedStoragePair(TensorLikePair):
    """Pair for :class:`torch.storage.TypedStorage` inputs."""
    def __init__(self, actual, expected, *, rtol_override=..., atol_override=..., **other_parameters) -> None:
        ...
    


class UnittestPair(Pair):
    """Fallback ABC pair that handles non-numeric inputs.

    To avoid recreating the mismatch messages of :meth:`unittest.TestCase.assertEqual`, this pair simply wraps it in
    order to use it with the :class:`Pair` "framework" from :func:`are_equal`.

    Define the :attr:`UnittestPair.CLS` in a subclass to indicate which class(es) of the inputs the pair should support.
    """
    CLS: Union[type, tuple[type, ...]]
    TYPE_NAME: Optional[str] = ...
    def __init__(self, actual, expected, **other_parameters) -> None:
        ...
    
    def compare(self): # -> None:
        ...
    


class StringPair(UnittestPair):
    CLS = ...
    TYPE_NAME = ...


class SetPair(UnittestPair):
    CLS = ...


class TypePair(UnittestPair):
    CLS = ...


class ObjectPair(UnittestPair):
    CLS = ...


class AssertRaisesContextIgnoreNotImplementedError(unittest.case._AssertRaisesContext):
    def __exit__(self, exc_type, exc_value, tb): # -> bool:
        ...
    


@contextmanager
def set_warn_always_context(new_val: bool): # -> Generator[None, Any, None]:
    ...

class NoTest:
    __test__ = ...


class TestCase(expecttest.TestCase):
    _precision: float = ...
    _rel_tol: float = ...
    _default_dtype_check_enabled: bool = ...
    _diffThreshold = ...
    maxDiff = ...
    @property
    def precision(self) -> float:
        ...
    
    @precision.setter
    def precision(self, prec: float) -> None:
        ...
    
    @property
    def rel_tol(self) -> float:
        ...
    
    @rel_tol.setter
    def rel_tol(self, prec: float) -> None:
        ...
    
    _do_cuda_memory_leak_check = ...
    _do_cuda_non_default_stream = ...
    _ignore_not_implemented_error = ...
    def __init__(self, method_name=..., methodName=...) -> None:
        ...
    
    def assertLeaksNoCudaTensors(self, name=...): # -> CudaMemoryLeakCheck:
        ...
    
    def enforceNonDefaultStream(self): # -> CudaNonDefaultStream:
        ...
    
    def remove_comment_lines(self, input_string): # -> LiteralString:
        ...
    
    def remove_empty_lines(self, input_string): # -> LiteralString:
        ...
    
    def assertExpectedInline(self, actual, expect, skip=..., ignore_comments=..., ignore_empty_lines=...):
        ...
    
    def assertExpectedInlineMunged(self, exc_type, callable, expect, *, skip=..., suppress_suffix=..., post_munge=...): # -> None:
        ...
    
    def assertLogs(self, logger=..., level=...):
        ...
    
    def assertNoLogs(self, logger=..., level=...):
        ...
    
    def wrap_with_cuda_policy(self, method_name, policy): # -> None:
        ...
    
    def wrap_with_policy(self, method_name, policy): # -> None:
        ...
    
    def wrap_method_with_policy(self, method, policy): # -> MethodType:
        ...
    
    def wrap_with_cuda_memory_check(self, method): # -> MethodType:
        ...
    
    def compile_fn(self, fn, backend, nopython): # -> OptimizedModule | type[Module] | type[Any] | _Wrapped[Callable[..., Any], object, Callable[..., Any], object] | Callable[..., object]:
        ...
    
    def run(self, result=...): # -> None:
        ...
    
    def setUp(self): # -> None:
        ...
    
    def tearDown(self): # -> None:
        ...
    
    def genSparseCompressedTensor(self, size, nnz, *, layout, device, dtype, index_dtype, blocksize=..., dense_dims=...): # -> Tensor:
        ...
    
    def genSparseCSRTensor(self, size, nnz, *, device, dtype, index_dtype, dense_dims=...): # -> Tensor:
        ...
    
    def genSparseCSCTensor(self, size, nnz, *, device, dtype, index_dtype, dense_dims=...): # -> Tensor:
        ...
    
    def genSparseBSRTensor(self, size, blocksize, nnz, *, device, dtype, index_dtype, dense_dims=...): # -> Tensor:
        ...
    
    def genSparseBSCTensor(self, size, blocksize, nnz, *, device, dtype, index_dtype, dense_dims=...): # -> Tensor:
        ...
    
    def genSparseTensor(self, size, sparse_dim, nnz, is_uncoalesced, device, dtype): # -> tuple[Any, Any, Any]:
        ...
    
    def generate_simple_inputs(self, layout, device=..., dtype=..., index_dtype=..., pin_memory=..., members_pin_memory=..., enable_batch=..., enable_hybrid=..., enable_zero_sized=..., enable_non_contiguous_indices=..., enable_non_contiguous_values=..., enable_batch_variable_nse=..., output_tensor=..., patterns=...):
        """Generator of simple inputs for tensor constructors of the given layout.

        The generated tensor inputs have the following properties:

        - tensor shapes are minimal but not trivial
        - tensor values are sorted sequences for COO and CSR formats, e.g. [1, 2, 3, 4]
        - the generated tensors represent the same mathematical tensor for all layouts
        - the generated tensors include regular, zero-sized, and optionally, batched or/and hybrid tensors.
        - the generated tensors include contiguous or non-contiguous tensors both in indices and values

        If output_tensor is True, yield tensors with the given
        layout. Otherwise, yield inputs to the corresponding tensor
        constructors:

          - sparse compressed input is defined as
            (compressed_indices, plain_indices, values), dict(size=expected_size_from_shape_inference, device=device, dtype=dtype,
                                                              pin_memory=pin_memory)

          - sparse COO input is defined as
            (indices, values), dict(size=expected_size_from_shape_inference, device=device, dtype=dtype, pin_memory=pin_memory)

          - strided input is defined as
            (values,), dict(device=device, dtype=dtype)
        """
        ...
    
    def safeToDense(self, t):
        ...
    
    def compare_with_reference(self, torch_fn, ref_fn, sample_input, **kwargs): # -> None:
        ...
    
    def compare_with_numpy(self, torch_fn, np_fn, tensor_like, device=..., dtype=..., **kwargs): # -> None:
        ...
    
    def assertEqualIgnoreType(self, *args, **kwargs) -> None:
        ...
    
    def assertEqualBroadcasting(self, x, y, *args, **kwargs) -> None:
        r"""Tests if tensor x equals to y, if y to be broadcast to x.shape.
        """
        ...
    
    def assertEqual(self, x, y, msg: Optional[Union[str, Callable[[str], str]]] = ..., *, atol: Optional[float] = ..., rtol: Optional[float] = ..., equal_nan=..., exact_dtype=..., exact_device=..., exact_layout=..., exact_stride=..., exact_is_coalesced=...): # -> None:
        ...
    
    def assertNotEqual(self, x, y, msg: Optional[str] = ..., *, atol: Optional[float] = ..., rtol: Optional[float] = ..., **kwargs) -> None:
        ...
    
    def assertEqualTypeString(self, x, y) -> None:
        ...
    
    def assertObjectIn(self, obj: Any, iterable: Iterable[Any]) -> None:
        ...
    
    def assertRaises(self, expected_exception, *args, **kwargs): # -> Any:
        ...
    
    def assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs): # -> Any:
        ...
    
    def assertNoUnraisable(self, callable, *args, **kwargs): # -> None:
        ...
    
    def assertExpectedRaises(self, exc_type, callable, *args, **kwargs): # -> None:
        ...
    
    def assertNotWarn(self, callable, msg=...): # -> None:
        r"""
        Test if :attr:`callable` does not raise a warning.
        """
        ...
    
    @contextmanager
    def assertWarnsOnceRegex(self, category, regex=...): # -> Generator[None, Any, None]:
        """Context manager for code that *must always* warn

        This filters expected warnings from the test and fails if
        the expected warning is not caught. It uses set_warn_always() to force
        TORCH_WARN_ONCE to behave like TORCH_WARN
        """
        ...
    
    def assertExpected(self, s, subname=...): # -> None:
        r"""
        Test that a string matches the recorded contents of a file
        derived from the name of this test and subname.  This file
        is placed in the 'expect' directory in the same directory
        as the test script. You can automatically update the recorded test
        output using --accept.

        If you call this multiple times in a single function, you must
        give a unique subname each time.
        """
        ...
    
    def assertExpectedStripMangled(self, s, subname=...): # -> None:
        ...
    
    def assertGreaterAlmostEqual(self, first, second, places=..., msg=..., delta=...): # -> None:
        """Assert that ``first`` is greater than or almost equal to ``second``.

        The equality of ``first`` and ``second`` is determined in a similar way to
        the ``assertAlmostEqual`` function of the standard library.
        """
        ...
    
    def assertAtenOp(self, onnx_model, operator, overload_name=...): # -> None:
        ...
    
    def check_nondeterministic_alert(self, fn, caller_name, should_alert=...): # -> None:
        '''Checks that an operation produces a nondeterministic alert when
        expected while `torch.use_deterministic_algorithms(True)` is set.

        Args:
          fn (callable): Function to check for a nondeterministic alert

          caller_name (str): Name of the operation that produces the
              nondeterministic alert. This name is expected to appear at the
              beginning of the error/warning message.

          should_alert (bool, optional): If True, then the check will only pass
              if calling `fn` produces a nondeterministic error/warning with the
              expected message. If False, then the check will only pass if
              calling `fn` does not produce an error. Default: `True`.
        '''
        ...
    
    @staticmethod
    def run_process_no_exception(code, env=...): # -> tuple[bytes, bytes]:
        ...
    
    @staticmethod
    def runWithPytorchAPIUsageStderr(code): # -> str:
        ...
    


class TestCaseBase(TestCase):
    ...


def download_file(url, binary=...): # -> str:
    ...

def find_free_port(): # -> _RetAddress:
    """
    Finds an available port and returns that port number.

    NOTE: If this function is being used to allocate a port to Store (or
    indirectly via init_process_group or init_rpc), it should be used
    in conjunction with the `retry_on_connect_failures` decorator as there is a potential
    race condition where the allocated port may become unavailable before it can be used
    """
    ...

ADDRESS_IN_USE = ...
CONNECT_TIMEOUT = ...
def retry_on_connect_failures(func=..., connect_errors=...): # -> partial[Any] | _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    """Reruns a test if the test returns a RuntimeError and the exception
    contains one of the strings in connect_errors."""
    ...

def retry(ExceptionToCheck, tries=..., delay=..., skip_after_retries=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def random_square_matrix_of_rank(l, rank, dtype=..., device=...):
    ...

def random_well_conditioned_matrix(*shape, dtype, device, mean=..., sigma=...):
    """
    Returns a random rectangular matrix (batch of matrices)
    with singular values sampled from a Gaussian with
    mean `mean` and standard deviation `sigma`.
    The smaller the `sigma`, the better conditioned
    the output matrix is.
    """
    ...

def noncontiguous_like(t):
    ...

def random_symmetric_matrix(l, *batches, **kwargs):
    ...

def make_symmetric_matrices(*shape, device, dtype):
    ...

def random_hermitian_matrix(l, *batches, **kwargs):
    ...

def random_symmetric_psd_matrix(l, *batches, **kwargs): # -> Tensor:
    """
    Returns a batch of random symmetric positive-semi-definite matrices.
    The shape of the result is batch_dims + (matrix_size, matrix_size)
    The following example creates a tensor of size 2 x 4 x 3 x 3
    >>> # xdoctest: +SKIP("undefined variables")
    >>> matrices = random_symmetric_psd_matrix(3, 2, 4, dtype=dtype, device=device)
    """
    ...

def random_hermitian_psd_matrix(matrix_size, *batch_dims, dtype=..., device=...): # -> Tensor:
    """
    Returns a batch of random Hermitian positive-semi-definite matrices.
    The shape of the result is batch_dims + (matrix_size, matrix_size)
    The following example creates a tensor of size 2 x 4 x 3 x 3
    >>> # xdoctest: +SKIP("undefined variables")
    >>> matrices = random_hermitian_psd_matrix(3, 2, 4, dtype=dtype, device=device)
    """
    ...

def random_symmetric_pd_matrix(matrix_size, *batch_dims, **kwargs):
    ...

def make_symmetric_pd_matrices(*shape, device, dtype):
    ...

def random_hermitian_pd_matrix(matrix_size, *batch_dims, dtype, device):
    """
    Returns a batch of random Hermitian positive-definite matrices.
    The shape of the result is batch_dims + (matrix_size, matrix_size)
    The following example creates a tensor of size 2 x 4 x 3 x 3
    >>> # xdoctest: +SKIP("undefined variables")
    >>> matrices = random_hermitian_pd_matrix(3, 2, 4, dtype=dtype, device=device)
    """
    ...

def make_fullrank_matrices_with_distinct_singular_values(*shape, device, dtype, requires_grad=...):
    ...

def random_matrix(rows, columns, *batch_dims, **kwargs): # -> Tensor:
    """Return rectangular matrix or batches of rectangular matrices.

    Parameters:
      dtype - the data type
      device - the device kind
      singular - when True, the output will be singular
    """
    ...

def random_lowrank_matrix(rank, rows, columns, *batch_dims, **kwargs):
    """Return rectangular matrix or batches of rectangular matrices with
    given rank.
    """
    ...

def random_sparse_matrix(rows, columns, density=..., **kwargs):
    """Return rectangular random sparse matrix within given density.

    The density of the result approaches to given density as the size
    of the matrix is increased and a relatively small value of density
    is specified but higher than min(rows, columns)/(rows * columns)
    for non-singular matrices.
    """
    ...

def random_sparse_pd_matrix(matrix_size, density=..., **kwargs):
    """Return random sparse positive-definite matrix with given density.

    The eigenvalues of the matrix are defined as::
      arange(1, matrix_size+1)/matrix_size

    Algorithm:
      A = diag(arange(1, matrix_size+1)/matrix_size)
      while <A density is smaller than required>:
          <choose random i, j in range(matrix_size), theta in [0, 2*pi]>
          R = <rotation matrix (i,j,theta)>
          A = R^T A R
    """
    ...

def do_test_dtypes(self, dtypes, layout, device): # -> None:
    ...

def do_test_empty_full(self, dtypes, layout, device): # -> None:
    ...

running_script_path = ...
def set_running_script_path(): # -> None:
    ...

def check_test_defined_in_running_script(test_case): # -> None:
    ...

def load_tests(loader, tests, pattern): # -> TestSuite:
    ...

class BytesIOContext(io.BytesIO):
    def __enter__(self): # -> Self:
        ...
    
    def __exit__(self, *args): # -> None:
        ...
    


GRADCHECK_NONDET_TOL = ...
TEST_WITH_SLOW_GRADCHECK: bool = ...
skipIfSlowGradcheckEnv = ...
def gradcheck(fn, inputs, **kwargs): # -> bool:
    ...

def gradgradcheck(fn, inputs, grad_outputs=..., **kwargs): # -> bool:
    ...

@contextmanager
def set_cwd(path: str) -> Iterator[None]:
    ...

dtype2prec_DONTUSE = ...
def coalescedonoff(f): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]:
    ...

def is_coalesced_indices(s): # -> bool:
    ...

@contextlib.contextmanager
def disable_gc(): # -> Generator[None, Any, None]:
    ...

def find_library_location(lib_name: str) -> Path:
    ...

def skip_but_pass_in_sandcastle(reason): # -> Callable[..., Any | _Wrapped[Callable[..., Any], Any, Callable[..., Any], None]]:
    """
    Similar to unittest.skip, however in the sandcastle environment it just
    "passes" the test instead to avoid creating tasks complaining about tests
    skipping continuously.
    """
    ...

def mock_wrapper(method): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    """
    Returns a function that calls the real implementation of a method
    in addition to passing args to a mock object.
    """
    ...

def get_tensors_from(args, kwargs): # -> set[Tensor]:
    """ Returns a set of all Tensor objects in the given args and kwargs. """
    ...

def bytes_to_scalar(byte_list: list[int], dtype: torch.dtype, device: torch.device): # -> Tensor:
    ...

def copy_func(f): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    """Based on http://stackoverflow.com/a/6528148/190597 (Glenn Maynard)"""
    ...

def xfail_inherited_tests(tests): # -> Callable[..., Any]:
    """
    Given a list of test names which are defined by a superclass of the
    class this decorates, mark them as expected failure.  This is useful
    if you are doing poor man's parameterized tests by subclassing a generic
    test class.
    """
    ...

def skip_but_pass_in_sandcastle_if(condition, reason): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], None] | Any]:
    """
    Similar to unittest.skipIf, however in the sandcastle environment it just
    "passes" the test instead to avoid creating tasks complaining about tests
    skipping continuously.
    """
    ...

def dtype_name(dtype): # -> str:
    """ Returns the pretty name of the dtype (e.g. torch.int64 -> int64). """
    ...

@functools.lru_cache
def get_cycles_per_ms() -> float:
    """Measure and return approximate number of cycles per millisecond for torch.cuda._sleep
    """
    ...

T = TypeVar('T')
def first_sample(self: unittest.TestCase, samples: Iterable[T]) -> T:
    """
    Returns the first sample from an iterable of samples, like those returned by OpInfo.
    The test will be skipped if no samples are available.
    """
    ...

def clone_input_helper(input): # -> Tensor | tuple[Any, ...]:
    ...

@contextmanager
def custom_op(opname, symbolic_fn, opset_version): # -> Generator[None, Any, None]:
    """Context manager/decorator to test ONNX export with custom operator"""
    ...

def outs_and_grads(fn, graph_inps, inps): # -> tuple[Any, list[Tensor | None]]:
    ...

def compare_equal_outs_and_grads(test, m1, m2, inps): # -> None:
    ...

class TestGradients(TestCase):
    exact_dtype = ...


def make_lazy_class(cls):
    ...

class NestedTensorTestCase(TestCase):
    def assertEqualIgnoringNestedInts(self, a, b): # -> None:
        ...
    
    def assertEqualNoncontigAware(self, a, b): # -> None:
        ...
    
    @contextlib.contextmanager
    def branch_nested_state(self): # -> Generator[None, Any, None]:
        """Context manager to branch and restore the nested tensor state."""
        ...
    


@make_lazy_class
class LazyVal:
    ...


def munge_exc(e, *, suppress_suffix=..., suppress_prefix=..., file=..., skip=...): # -> str:
    ...

@contextmanager
def check_leaked_tensors(limit=..., matched_type=...): # -> Generator[list[Any], Any, None]:
    """Wrap around operations you want to ensure are not leaking tensor memory.

    This code intentionally ignores other reference cycles, which can be benign and which we have plenty
    of in pytorch code.  It focuses on any reference cycles that directly or indirectly result holding a Tensor alive,
    since this is likely a more serious leak than typical python refcycles.

    limit specifies how many tensors to dump debug graphs for (default=1)
    """
    ...

def remove_cpp_extensions_build_root(): # -> None:
    """
    Removes the default root folder under which extensions are built.
    """
    ...

def install_cpp_extension(extension_root): # -> None:
    ...

def scoped_load_inline(func): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def recover_orig_fp32_precision(fn):
    ...


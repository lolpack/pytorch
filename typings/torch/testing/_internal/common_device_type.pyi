"""
This type stub file was generated by pyright.
"""

import torch
from collections.abc import Sequence
from enum import Enum
from typing import Any, Callable, ClassVar, Optional, TypeVar, Union
from typing_extensions import ParamSpec
from torch.testing._internal.common_utils import TestCase, _TestParametrizer

_T = TypeVar("_T")
_P = ParamSpec("_P")
HAS_PSUTIL = ...
class DeviceTypeTestBase(TestCase):
    device_type: str = ...
    _stop_test_suite = ...
    _tls = ...
    @property
    def precision(self): # -> Any:
        ...
    
    @precision.setter
    def precision(self, prec): # -> None:
        ...
    
    @property
    def rel_tol(self): # -> Any:
        ...
    
    @rel_tol.setter
    def rel_tol(self, prec): # -> None:
        ...
    
    @classmethod
    def get_primary_device(cls): # -> str:
        ...
    
    @classmethod
    def get_all_devices(cls): # -> list[str]:
        ...
    
    @classmethod
    def instantiate_test(cls, name, test, *, generic_cls=...): # -> None:
        ...
    
    def run(self, result=...): # -> None:
        ...
    


class CPUTestBase(DeviceTypeTestBase):
    device_type = ...


class CUDATestBase(DeviceTypeTestBase):
    device_type = ...
    _do_cuda_memory_leak_check = ...
    _do_cuda_non_default_stream = ...
    primary_device: ClassVar[str]
    cudnn_version: ClassVar[Any]
    no_magma: ClassVar[bool]
    no_cudnn: ClassVar[bool]
    def has_cudnn(self): # -> bool:
        ...
    
    @classmethod
    def get_primary_device(cls): # -> str:
        ...
    
    @classmethod
    def get_all_devices(cls): # -> list[str]:
        ...
    
    @classmethod
    def setUpClass(cls): # -> None:
        ...
    


lazy_ts_backend_init = ...
class LazyTestBase(DeviceTypeTestBase):
    device_type = ...
    @classmethod
    def setUpClass(cls): # -> None:
        ...
    


class MPSTestBase(DeviceTypeTestBase):
    device_type = ...
    primary_device: ClassVar[str]
    @classmethod
    def get_primary_device(cls): # -> str:
        ...
    
    @classmethod
    def get_all_devices(cls): # -> list[str]:
        ...
    
    @classmethod
    def setUpClass(cls): # -> None:
        ...
    


class XPUTestBase(DeviceTypeTestBase):
    device_type = ...
    primary_device: ClassVar[str]
    @classmethod
    def get_primary_device(cls): # -> str:
        ...
    
    @classmethod
    def get_all_devices(cls): # -> list[str]:
        ...
    
    @classmethod
    def setUpClass(cls): # -> None:
        ...
    


class HPUTestBase(DeviceTypeTestBase):
    device_type = ...
    primary_device: ClassVar[str]
    @classmethod
    def get_primary_device(cls): # -> str:
        ...
    
    @classmethod
    def setUpClass(cls): # -> None:
        ...
    


class PrivateUse1TestBase(DeviceTypeTestBase):
    primary_device: ClassVar[str]
    device_mod = ...
    device_type = ...
    @classmethod
    def get_primary_device(cls): # -> str:
        ...
    
    @classmethod
    def get_all_devices(cls): # -> list[str]:
        ...
    
    @classmethod
    def setUpClass(cls): # -> None:
        ...
    


def get_device_type_test_bases(): # -> list[Any]:
    ...

device_type_test_bases = ...
def filter_desired_device_types(device_type_test_bases, except_for=..., only_for=...): # -> list[Any]:
    ...

_TORCH_TEST_DEVICES = ...
if _TORCH_TEST_DEVICES:
    ...
PYTORCH_CUDA_MEMCHECK = ...
PYTORCH_TESTING_DEVICE_ONLY_FOR_KEY = ...
PYTORCH_TESTING_DEVICE_EXCEPT_FOR_KEY = ...
PYTORCH_TESTING_DEVICE_FOR_CUSTOM_KEY = ...
def get_desired_device_type_test_bases(except_for=..., only_for=..., include_lazy=..., allow_mps=..., allow_xpu=...): # -> list[Any]:
    ...

def instantiate_device_type_tests(generic_test_class, scope, except_for=..., only_for=..., include_lazy=..., allow_mps=..., allow_xpu=...): # -> None:
    ...

class OpDTypes(Enum):
    supported = ...
    unsupported = ...
    supported_backward = ...
    unsupported_backward = ...
    any_one = ...
    none = ...
    any_common_cpu_cuda_one = ...


ANY_DTYPE_ORDER = ...
class ops(_TestParametrizer):
    def __init__(self, op_list, *, dtypes: Union[OpDTypes, Sequence[torch.dtype]] = ..., allowed_dtypes: Optional[Sequence[torch.dtype]] = ..., skip_if_dynamo=...) -> None:
        ...
    


class skipIf:
    def __init__(self, dep, reason, device_type=...) -> None:
        ...
    
    def __call__(self, fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
        ...
    


class skipCPUIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipCUDAIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipXPUIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipGPUIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipLazyIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipMetaIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipMPSIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipHPUIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipXLAIf(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


class skipPRIVATEUSE1If(skipIf):
    def __init__(self, dep, reason) -> None:
        ...
    


def largeTensorTest(size, device=..., inductor=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    """Skip test if the device has insufficient memory to run the test

    size may be a number of bytes, a string of the form "N GB", or a callable

    If the test is a device generic test, available memory on the primary device will be checked.
    It can also be overridden by the optional `device=` argument.
    In other tests, the `device=` argument needs to be specified.
    """
    ...

class expectedFailure:
    def __init__(self, device_type) -> None:
        ...
    
    def __call__(self, fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
        ...
    


class onlyOn:
    def __init__(self, device_type) -> None:
        ...
    
    def __call__(self, fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
        ...
    


class deviceCountAtLeast:
    def __init__(self, num_required_devices) -> None:
        ...
    
    def __call__(self, fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
        ...
    


def onlyNativeDeviceTypes(fn: Callable[_P, _T]) -> Callable[_P, _T]:
    ...

def onlyNativeDeviceTypesAnd(devices=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

class precisionOverride:
    def __init__(self, d) -> None:
        ...
    
    def __call__(self, fn):
        ...
    


tol = ...
class toleranceOverride:
    def __init__(self, d) -> None:
        ...
    
    def __call__(self, fn):
        ...
    


class dtypes:
    def __init__(self, *args, device_type=...) -> None:
        ...
    
    def __call__(self, fn):
        ...
    


class dtypesIfCPU(dtypes):
    def __init__(self, *args) -> None:
        ...
    


class dtypesIfCUDA(dtypes):
    def __init__(self, *args) -> None:
        ...
    


class dtypesIfMPS(dtypes):
    def __init__(self, *args) -> None:
        ...
    


class dtypesIfHPU(dtypes):
    def __init__(self, *args) -> None:
        ...
    


class dtypesIfPRIVATEUSE1(dtypes):
    def __init__(self, *args) -> None:
        ...
    


def onlyCPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def onlyCUDA(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def onlyMPS(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def onlyXPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def onlyHPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def onlyPRIVATEUSE1(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def onlyCUDAAndPRIVATEUSE1(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def disablecuDNN(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def disableMkldnn(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def expectedFailureCPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def expectedFailureCUDA(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def expectedFailureXPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def expectedFailureMeta(fn): # -> _Wrapped[Callable[..., Any], Any | None, Callable[..., Any], None] | <subclass of _Wrapped[..., Unknown, (slf: Unknown, ...), Unknown | None] and type>:
    ...

def expectedFailureXLA(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def expectedFailureHPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def expectedFailureMPS(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def expectedFailureMPSPre15(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def expectedFailureMPSPre14(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
    ...

def skipCPUIfNoLapack(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCPUIfNoFFT(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCPUIfNoMkl(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCPUIfNoMklSparse(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCPUIfNoMkldnn(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfNoMagma(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def has_cusolver(): # -> bool:
    ...

def has_hipsolver(): # -> bool:
    ...

def skipCUDAIfNoCusolver(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfNoMagmaAndNoCusolver(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfNoMagmaAndNoLinalgsolver(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfRocm(func=..., *, msg=...): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any] | Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipCUDAIfNotRocm(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfRocmVersionLessThan(version=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipCUDAIfNotMiopenSuggestNHWC(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAVersionIn(versions: Optional[list[tuple[int, int]]] = ...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipCUDAIfVersionLessThan(versions: Optional[tuple[int, int]] = ...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipCUDAIfCudnnVersionLessThan(version=...): # -> Callable[..., _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]]:
    ...

def skipCUDAIfNoCusparseGeneric(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfNoHipsparseGeneric(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfNoSparseGeneric(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfNoCudnn(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfMiopen(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipCUDAIfNoMiopen(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipLazy(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipMeta(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipXLA(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipMPS(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipHPU(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def skipPRIVATEUSE1(fn): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
    ...

def get_all_device_types() -> list[str]:
    ...

IS_FLEX_ATTENTION_CPU_PLATFORM_SUPPORTED = ...
flex_attention_supported_platform = ...
if torch.version.hip and "gfx94" in torch.cuda.get_device_properties(0).gcnArchName:
    e4m3_type = ...
    e5m2_type = ...
    E4M3_MAX_POS = ...
    E5M2_MAX_POS = ...
else:
    e4m3_type = ...
    e5m2_type = ...
    E4M3_MAX_POS = ...
    E5M2_MAX_POS = ...

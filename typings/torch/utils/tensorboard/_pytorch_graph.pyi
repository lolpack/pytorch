"""
This type stub file was generated by pyright.
"""

methods_OP = ...
methods_IO = ...
GETATTR_KIND = ...
CLASSTYPE_KIND = ...
class NodeBase:
    def __init__(self, debugName=..., inputs=..., scope=..., tensor_size=..., op_type=..., attributes=...) -> None:
        ...
    
    def __repr__(self): # -> LiteralString:
        ...
    


class NodePy(NodeBase):
    def __init__(self, node_cpp, valid_methods) -> None:
        ...
    


class NodePyIO(NodePy):
    def __init__(self, node_cpp, input_or_output=...) -> None:
        ...
    


class NodePyOP(NodePy):
    def __init__(self, node_cpp) -> None:
        ...
    


class GraphPy:
    """Helper class to convert torch.nn.Module to GraphDef proto and visualization with TensorBoard.

    GraphDef generation operates in two passes:

    In the first pass, all nodes are read and saved to two lists.
    One list is for input/output nodes (nodes_io), which only have inbound
    or outbound connections, but not both. Another list is for internal
    operator nodes (nodes_op). The first pass also saves all scope name
    appeared in the nodes in scope_name_appeared list for later processing.

    In the second pass, scope names are fully applied to all nodes.
    debugNameToScopedName is a mapping from a node's ID to its fully qualified
    scope name. e.g. Net1/Linear[0]/1. Unfortunately torch.jit doesn't have
    totally correct scope output, so this is nontrivial. The function
    populate_namespace_from_OP_to_IO and find_common_root are used to
    assign scope name to a node based on the connection between nodes
    in a heuristic kind of way. Bookkeeping is done with shallowest_scope_name
    and scope_name_appeared.
    """
    def __init__(self) -> None:
        ...
    
    def append(self, x): # -> None:
        ...
    
    def printall(self): # -> None:
        ...
    
    def find_common_root(self): # -> None:
        ...
    
    def populate_namespace_from_OP_to_IO(self): # -> None:
        ...
    
    def to_proto(self): # -> list[Any]:
        """Convert graph representation of GraphPy object to TensorBoard required format."""
        ...
    


def parse(graph, trace, args=..., omit_useless_nodes=...): # -> list[Any]:
    """Parse an optimized PyTorch model graph and produces a list of nodes and node stats.

    Useful for eventual conversion to TensorBoard protobuf format.

    Args:
      graph (PyTorch module): The model graph to be parsed.
      trace (PyTorch JIT TracedModule): The model trace to be parsed.
      args (tuple): input tensor[s] for the model.
      omit_useless_nodes (boolean): Whether to remove nodes from the graph.
    """
    ...

def graph(model, args, verbose=..., use_strict_trace=...): # -> tuple[Any, Any]:
    """
    Process a PyTorch model and produces a `GraphDef` proto that can be logged to TensorBoard.

    Args:
      model (PyTorch module): The model to be parsed.
      args (tuple): input tensor[s] for the model.
      verbose (bool): Whether to print out verbose information while
        processing.
      use_strict_trace (bool): Whether to pass keyword argument `strict` to
        `torch.jit.trace`. Pass False when you want the tracer to
        record your mutable container types (list, dict)
    """
    ...


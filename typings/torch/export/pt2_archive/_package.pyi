"""
This type stub file was generated by pyright.
"""

import logging
import torch
from dataclasses import dataclass
from typing import Any, Optional, TYPE_CHECKING, Union
from typing_extensions import TypeAlias
from torch.export.exported_program import ExportedProgram
from torch.export.pt2_archive._package_weights import Weights
from torch.types import FileLike

if TYPE_CHECKING:
    ...
DEFAULT_PICKLE_PROTOCOL = ...
AOTI_FILES: TypeAlias = Union[list[Union[str, Weights]], dict[str, list[Union[str, Weights]]]]
logger: logging.Logger = ...
def is_pt2_package(serialized_model: Union[bytes, str]) -> bool:
    """
    Check if the serialized model is a PT2 Archive package.
    """
    ...

class PT2ArchiveWriter:
    """
    Context manager for writing a PT2 archive.
    """
    def __init__(self, archive_path_or_buffer: FileLike) -> None:
        ...
    
    def __enter__(self) -> PT2ArchiveWriter:
        ...
    
    def __exit__(self, *args: Any) -> None:
        ...
    
    def has_record(self, name: str) -> bool:
        """
        Check if a record exists in the archive.
        """
        ...
    
    def count_prefix(self, prefix: str) -> int:
        """
        Count the number of records that start with a given prefix.
        """
        ...
    
    def write_bytes(self, name: str, data: bytes) -> None:
        """
        Write a bytes object to the archive.
        name: The destination file inside the archive.
        data: The bytes object to write.
        """
        ...
    
    def write_string(self, name: str, data: str) -> None:
        """
        Write a string object to the archive.
        name: The destination file inside the archive.
        data: The string object to write.
        """
        ...
    
    def write_file(self, name: str, file_path: str) -> None:
        """
        Copy a file into the archive.
        name: The destination file inside the archive.
        file_path: The source file on disk.
        """
        ...
    
    def write_folder(self, archive_dir: str, folder_dir: str) -> None:
        """
        Copy a folder into the archive.
        archive_dir: The destination folder inside the archive.
        folder_dir: The source folder on disk.
        """
        ...
    
    def close(self) -> None:
        """
        Close the archive.
        """
        ...
    


class PT2ArchiveReader:
    """
    Context manager for reading a PT2 archive.
    """
    def __init__(self, archive_path_or_buffer: FileLike) -> None:
        ...
    
    def __enter__(self) -> PT2ArchiveReader:
        ...
    
    def __exit__(self, *args: Any) -> None:
        ...
    
    def read_bytes(self, name: str) -> bytes:
        """
        Read a bytes object from the archive.
        name: The source file inside the archive.
        """
        ...
    
    def read_string(self, name: str) -> str:
        """
        Read a string object from the archive.
        name: The source file inside the archive.
        """
        ...
    
    def archive_version(self) -> int:
        """
        Get the archive version.
        """
        ...
    
    def get_file_names(self) -> list[str]:
        """
        Get the file names in the archive.
        """
        ...
    


def package_pt2(f: FileLike, *, exported_programs: Optional[Union[ExportedProgram, dict[str, ExportedProgram]]] = ..., aoti_files: Optional[AOTI_FILES] = ..., extra_files: Optional[dict[str, Any]] = ..., opset_version: Optional[dict[str, int]] = ..., pickle_protocol: int = ...) -> FileLike:
    """
    Saves the artifacts to a PT2Archive format
    (https://docs.google.com/document/d/1RQ4cmywilnFUT1VE-4oTGxwXdc8vowCSZsrRgo3wFA8/edit?tab=t.0#heading=h.v2y2jgnwc56a).
    The artifact can then be loaded using ``load_pt2``.

    Args:
        f (str | os.PathLike[str] | IO[bytes]) A file-like object (has to
         implement write and flush) or a string containing a file name.

        exported_programs (Union[ExportedProgram, dict[str, ExportedProgram]]):
         The exported program to save, or a dictionary mapping model name to an
         exported program to save. The exported program will be saved under
         models/*.json. If only one ExportedProgram is specified, this will
         automatically be named "model".

        aoti_files (Union[list[str], dict[str, list[str]]): A list of files
         generated by AOTInductor via
         ``torch._inductor.aot_compile(..., {"aot_inductor.package": True})``,
         or a dictionary mapping model name to its AOTInductor generated files.
         If only one set of files is specified, this will automatically be named
         "model".

        extra_files (Optional[Dict[str, Any]]): Map from filename to contents
         which will be stored as part of the pt2.

        opset_version (Optional[Dict[str, int]]): A map of opset names
         to the version of this opset

        pickle_protocol: can be specified to override the default protocol

    """
    ...

class AOTICompiledModel:
    """
    Callable AOT Inductor loaded model from a .pt2
    """
    def __init__(self, loader: torch._C._aoti.AOTIModelPackageLoader) -> None:
        ...
    
    def __call__(self, *args, **kwargs): # -> PyTree:
        ...
    
    def get_metadata(self) -> dict[str, str]:
        ...
    
    def load_constants(self, constants_map: dict[str, torch.Tensor], *, check_full_update: bool, user_managed: bool = ...) -> None:
        """
        Given a mapping of constant fqns to tensors, load the constants into the model.
        You can use ``get_constant_fqns`` to get the list of constant fqns that
        are needed in the compiled model.

        Args:
            constants_map: A mapping of constant fqns to tensors.
            check_full_update: Whether to add check to see if all the constants
            are updated and have values.
        """
        ...
    
    def get_constant_fqns(self) -> list[str]:
        ...
    
    def __deepcopy__(self, memo: Optional[dict[Any, Any]]) -> AOTICompiledModel:
        ...
    


@dataclass
class PT2ArchiveContents:
    exported_programs: dict[str, ExportedProgram]
    aoti_runners: dict[str, AOTICompiledModel]
    extra_files: dict[str, Any]
    ...


def load_pt2(f: FileLike, *, expected_opset_version: Optional[dict[str, int]] = ..., run_single_threaded: bool = ..., num_runners: int = ..., device_index: int = ..., load_weights_from_disk: bool = ...) -> PT2ArchiveContents:
    """
    Loads all the artifacts previously saved with ``package_pt2``.

    Args:
        f (str | os.PathLike[str] | IO[bytes]): A file-like object (has to
         implement write and flush) or a string containing a file name.

        expected_opset_version (Optional[Dict[str, int]]): A map of opset names
         to expected opset versions

        num_runners (int): Number of runners to load AOTInductor artifacts

        run_single_threaded (bool): Whether the model should be run without
            thread synchronization logic. This is useful to avoid conflicts with
            CUDAGraphs.

        device_index (int): The index of the device to which the PT2 package is
            to be loaded. By default, `device_index=-1` is used, which corresponds
            to the device `cuda` when using CUDA. Passing `device_index=1` would
            load the package to `cuda:1`, for example.

    Returns:
        A ``PT2ArchiveContents`` object which contains all the objects in the PT2.
    """
    ...

def load_weights_to_pt2_contents(pt2_contents: PT2ArchiveContents, weights_map: dict[str, Any]) -> None:
    """
    Load weights into the models in PT2 archive contents

    Args:
        pt2_contents (PT2ArchiveContents): The contents of the PT2 archive.
    """
    ...


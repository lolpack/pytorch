"""
This type stub file was generated by pyright.
"""

import torch
import torch.fx as fx
from dataclasses import dataclass
from typing import Callable

is_tuple = ...
@dataclass
class LoadTensorMeta:
    size: list[int]
    stride: list[int]
    dtype: torch.dtype
    device: torch.device
    ...


class ConcreteProp(torch.fx.Interpreter):
    def __init__(self, mod, *, writer=..., skip_offload=...) -> None:
        ...
    
    def run_node(self, n): # -> Tensor | Any:
        ...
    
    def propagate(self, *args): # -> Any:
        ...
    


def is_load_tensor_node(node): # -> bool:
    ...

def create_minified_hlo_graph(minified_fx_graph, inputs): # -> None:
    """
    Takes minified FX graph as primary input, and ports it to HLO via StableHLO
    Provides minified HLO graph as output, and archive them to local directory
    """
    ...

def dump_state(fx_g, inps): # -> None:
    ...

def is_power_of_two(n): # -> Literal[False]:
    ...

@dataclass
class ReproState:
    graph: fx.Graph
    inps: list[torch.Tensor]
    def __post_init__(self): # -> None:
        ...
    


def minifier(fail_f: fx.GraphModule, inps, module_fails, dump_state: Callable = ..., *, save_dir=..., offload_to_disk=..., skip_offload=..., skip_sanity=..., max_granularity=...): # -> tuple[GraphModule, Any | list[Tensor]]:
    """
    Minimizes a FX graph with given inputs, such that the resulting FX graph still returns True for module_fails.

    Does 2 main strategies:
    1. Truncates suffix: Removes some suffix from the graph and sets a new output.
    2. Delta Debugging: Tries replacing half of the graph with inputs. If fails,
        tries replacing quarter of the graph, etc.

    >>> # xdoctest: +SKIP(failing)
    >>> failing_function = fx.symbolic_trace(f)
    >>> minimize(failing_function, [torch.randn(5)], lambda fx_g, inps: fx_g(*inps))

    note: module_fails returns True if it fails.
    """
    ...


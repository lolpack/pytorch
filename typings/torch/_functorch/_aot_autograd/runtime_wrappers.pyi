"""
This type stub file was generated by pyright.
"""

import torch
from dataclasses import dataclass
from typing import Any, Callable, Optional, TYPE_CHECKING, Union
from torch import Tensor
from torch._guards import CompileContext, TracingContext
from .schemas import AOTConfig, InputAliasInfo, MemoryFormatMeta, PlainTensorMeta, SubclassCreationMeta, SubclassMeta, ViewAndMutationMeta

"""
This module defines runtime wrappers, which, based on previous analysis attempts to:
1. process the inputs and outputs
2. apply mutations
3. handle functionalized randomness
4. deduplicate inputs and consolidate views into their bases (see input_output_analysis)
"""
if TYPE_CHECKING:
    ...
zip = ...
class CompilerWrapper:
    """
    A wrapper around the inputs and outputs to the compiler_fn. We separate these into two parts:

    1. The prologue, which edits the input to the compiler_fn(flat_fn, flat_args, etc)
    2. The epilogue, which edits the outputs of the compiler_fn (compiled_fn, real arguments)

    Each wrapper below should be implemented as a CompilerWrapper, so that we can facilitate
    caching on the compiled output, and re-wrapping the output via epilogues.
    Extra metadata that is needed to compute pre or post compile can be passed in via attributes.
    """
    def pre_compile(self, flat_fn, flat_args: list[Tensor], aot_config: AOTConfig, *, fw_metadata: ViewAndMutationMeta) -> tuple[Callable, list[Tensor], ViewAndMutationMeta]:
        """
        Process the inputs to the compiler_fn. You can pass in extra metadata via kwargs.
        Args:
        flat_fn: The function to compile
        flat_args: Metadata from example inputs of the function to compile
        aot_config: AOTConfig passed in at compile time
        fw_metadata: ViewAndMutationMeta generated from flat_fn and flat_args
        """
        ...
    
    def post_compile(self, compiled_fn, aot_config, *, runtime_metadata) -> Callable:
        """
        Given an output of the compiler, wrap it with information received from prologue.
        Args:
        compiled_fn: Callable after calling compiler_fn
        aot_config: AOTConfig after calling prologue
        runtime_metadata: ViewAndMutationMeta after calling all wrappers's pre_compile steps.
        Example:

        def wrapped_compiled_fn(args):
            # do something with args, aot_config, fw_metadata
            return compiled_fn(args)

        return wrapped_compiled_fn
        """
        ...
    


@dataclass
class RuntimeWrapper(CompilerWrapper):
    indices_of_inps_to_detach: list[int]
    trace_joint: bool
    disable_amp: bool
    def post_compile(self, compiled_fn, aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta): # -> Callable[..., list[Any]]:
        ...
    


class NoopAliasHandler:
    def __init__(self, info, runtime_metadata, trace_joint) -> None:
        ...
    
    def __call__(self, orig_inputs, fw_outs, out):
        ...
    


class AliasOfInputHandler:
    def __init__(self, info, runtime_metadata, trace_joint) -> None:
        ...
    
    def __call__(self, orig_inputs, fw_outs, out): # -> Tensor:
        ...
    


class IsInputHandler:
    def __init__(self, info, runtime_metadata, trace_joint) -> None:
        ...
    
    def __call__(self, orig_inputs, fw_outs, out):
        ...
    


class AliasOfIntermediateHandler:
    def __init__(self, info, runtime_metadata, trace_joint) -> None:
        ...
    
    def __call__(self, orig_inputs, fw_outs, out): # -> Tensor:
        ...
    


_HANDLER_MAP = ...
def make_output_handler(info, runtime_metadata, trace_joint):
    ...

def maybe_mark_dynamic_helper(t: torch.Tensor, dims: set[int]): # -> None:
    ...

@dataclass
class FunctionalizedRngRuntimeWrapper(CompilerWrapper):
    return_new_outs: bool = ...
    def pre_compile(self, flat_fn, flat_args, aot_config, *, fw_metadata) -> tuple[Callable, list[Tensor], ViewAndMutationMeta]:
        ...
    
    def post_compile(self, compiled_fn, aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
        ...
    


@dataclass
class FakifiedOutWrapper(CompilerWrapper):
    out_metas: list[torch.Tensor] = ...
    fwd_output_strides: Optional[list[Optional[list[int]]]] = ...
    needs_post_compile: bool = ...
    def pre_compile(self, fw_module, flat_args, aot_config, *, fw_metadata) -> tuple[Callable, list[Tensor], ViewAndMutationMeta]:
        ...
    
    def set_fwd_output_strides(self, fwd_output_strides): # -> None:
        ...
    
    def post_compile(self, compiled_fn, aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], list[Tensor] | Any]:
        ...
    


@dataclass
class AOTDispatchSubclassWrapper(CompilerWrapper):
    trace_joint: bool
    fw_only: Optional[Callable]
    maybe_subclass_meta: Optional[SubclassMeta]
    num_fw_outs_saved_for_bw: Optional[int]
    def pre_compile(self, flat_fn, flat_args: list[Tensor], aot_config: AOTConfig, *, fw_metadata: ViewAndMutationMeta): # -> tuple[Any, Any, ViewAndMutationMeta]:
        ...
    
    def post_compile(self, compiled_fn, _aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], tuple[Any, ...]]:
        ...
    


@dataclass
class EffectTokensWrapper(CompilerWrapper):
    def post_compile(self, compiled_fn, _aot_config, *, runtime_metadata: ViewAndMutationMeta): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any | None]:
        ...
    


@dataclass
class AOTDedupeWrapper(CompilerWrapper):
    keep_arg_mask: list[bool] = ...
    add_dupe_map: list[int] = ...
    old_input_metadata: list[InputAliasInfo] = ...
    needs_post_compile: bool = ...
    def remove_dupe_args(self, args): # -> list[Any]:
        ...
    
    def add_dupe_args(self, args): # -> list[Any]:
        ...
    
    def pre_compile(self, flat_fn, flat_args: list[Tensor], aot_config: AOTConfig, *, fw_metadata: ViewAndMutationMeta) -> tuple[Callable, list[Tensor], ViewAndMutationMeta]:
        ...
    
    def post_compile(self, compiled_fn, aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
        ...
    


@dataclass
class AOTSyntheticBaseWrapper(CompilerWrapper):
    trace_joint: bool
    needs_post_compile: bool = ...
    aliased_arg_idx_with_metadata_mutations: list[int] = ...
    def pre_compile(self, flat_fn, flat_args: list[Any], aot_config: AOTConfig, *, fw_metadata: ViewAndMutationMeta) -> tuple[Callable, list[Tensor], ViewAndMutationMeta]:
        ...
    
    def post_compile(self, compiled_fn, aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
        ...
    


def merge_view_inputs(aot_config: AOTConfig, fwd_inputs: list[Any], mutated_input_info: list[InputAliasInfo], *, is_inference: bool) -> tuple[list[Any], Optional[list[Union[int, tuple[int, torch.Tensor]]]]]:
    ...

@dataclass
class AutogradLazyBackwardCompileInfo:
    bw_module: Callable
    placeholder_list: list[Any]
    saved_context: Optional[TracingContext]
    saved_compile_context: Optional[CompileContext]
    ...


@dataclass
class CachedAutogradLazyBackwardCompileInfo:
    bw_module_fn: Callable
    ...


def initialize_rng_states(num_rng: int, graphsafe_idx: int, fwd_rng_states: list[torch.Generator], bwd_rng_states: list[torch.Generator]): # -> None:
    """
    Initialize the cudagraph safe rng states.

    Initialization of rng states should have a few properties:
    - the initialization for each rng state should be independent
    - the initialization should be deterministic
    - the initialization should be based off current rng state, so that independent graphs do not
    have equal rng behavior

    We defer initialization of rng states until runtime because compilation is wrapped
    with preserve_rng_states. Seed initialization should advance the rng states so consecutive compilations
    do not give equal randomness.
    """
    ...

def coerce_to_expected_memory_format(x: torch.Tensor, memory_format: MemoryFormatMeta): # -> Tensor:
    ...

class AOTDispatchAutograd:
    @staticmethod
    def process_runtime_tangent(x, meta: Union[PlainTensorMeta, SubclassCreationMeta]): # -> tuple[Any, list[Any]] | tuple[Any | Tensor, list[Any | Tensor]] | tuple[TensorWithFlatten, list[Any]]:
        ...
    
    @staticmethod
    def post_compile(compiled_fw_func, compiled_bw_func, maybe_subclass_meta: Optional[SubclassMeta], num_symints_saved_for_bw_: int, backward_state_indices: list[int], disable_amp: bool, indices_of_inps_to_detach: list[int], lazy_backward_info: Optional[Union[AutogradLazyBackwardCompileInfo, CachedAutogradLazyBackwardCompileInfo,]], aot_config: AOTConfig, *, fw_metadata: ViewAndMutationMeta, try_save_cache_entry: Optional[Callable]): # -> Callable[..., list[Any]]:
        class CompiledFunction(torch.autograd.Function):
            ...
        
        
    


@dataclass
class DebugAssertWrapper(CompilerWrapper):
    flat_requires_grad: list[Optional[bool]] = ...
    def post_compile(self, compiled_fn, aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta): # -> _Wrapped[Callable[..., Any], Any, Callable[..., Any], Any]:
        ...
    


def pre_compile(wrappers: list[CompilerWrapper], flat_fn: Callable, flat_args: list[Any], aot_config: AOTConfig, *, fw_metadata: ViewAndMutationMeta) -> tuple[Callable, list[Tensor], ViewAndMutationMeta]:
    """
    Runs a sequence of wrappers on the given function and arguments.
    Mutates wrappers in place.
    """
    ...

def post_compile(wrappers: list[CompilerWrapper], compiled_fn: Callable, aot_config: AOTConfig, *, runtime_metadata: ViewAndMutationMeta) -> tuple[Callable, ViewAndMutationMeta]:
    """
    Runs a sequence of wrappers on the given function. Should be called after pre_compile()
    """
    ...

def make_runtime_safe(fw_metadata: ViewAndMutationMeta, maybe_subclass_meta: Optional[SubclassMeta]): # -> None:
    """
    Calls make_runtime_safe on all ViewAndMutationMetas.
    Modifies both arguments. Allows ViewAndMutationMetas to
    be safely cached in AOTAutogradCache.
    """
    ...


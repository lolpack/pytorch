"""
This type stub file was generated by pyright.
"""

import torch
import torch.fx
from dataclasses import dataclass
from typing import Callable, Optional
from torch.fx._compatibility import compatibility
from .tools_common import Names, NodeList, NodeSet, TensorOrTensors, Tensors

__all__ = ["FxNetMinimizerBadModuleError", "FxNetMinimizerRunFuncError", "FxNetMinimizerResultMismatchError"]
_LOGGER = ...
@compatibility(is_backward_compatible=False)
class FxNetMinimizerBadModuleError(Exception):
    """
    Raised if failed to split out a minimize module
    """
    ...


@compatibility(is_backward_compatible=False)
class FxNetMinimizerRunFuncError(Exception):
    """
    Raised if error occurs during run_a or run_b functions
    """
    ...


@compatibility(is_backward_compatible=False)
class FxNetMinimizerResultMismatchError(Exception):
    """
    Raised if comparing function thinks the results are mismatching.
    """
    ...


@dataclass
class _MinimizerSettingBase:
    """
    Args:
    `accumulate_error`: Instead of using a's input for both converted module to verify
    , use the previous outputs of each converted module as input to accumulate the
    errors.

    `traverse_method`: "sequential" or "binary" or "accumulate"
    Determine the way of traverse the nodes in FX module.

    `find_all`: Minimizer will go through the entire model and return all problematic nodes.

    `return_intermediate`: If true, when using `run_nodes()` function to run the
    model, intermediate results of all the ops will be returned as output.

    `all_outputs`: If true, when using `_run_and_compare()` function,
    all the output nodes in the subgraph will be used for comparison.
    """
    accumulate_error: bool = ...
    traverse_method: str = ...
    find_all: bool = ...
    return_intermediate: bool = ...
    all_outputs: bool = ...
    def __str__(self) -> str:
        ...
    


class _MinimizerBase:
    """
    This class is used to automatically find problematic nodes in a model. It takes a FX
    graphmodule and generate some submodules while traverse the graph. Then two functions
    `run_a` and `run_b` will be used to run the same submodule and a function `compare_fn`
    will be used to compare the results.

    Currently we provides two ways to traverse the graph and generate submodules.
        1. Sequential traversal: this will traverse the graph node by node and generate
           one submodule with one sigle node.
        2. Binary searching: this will do a binary search style traversal on the graph.

    For internal Users, a guide can be found here https://fb.quip.com/HDtuAgiKGfkP.
    """
    def __init__(self, module: torch.fx.GraphModule, sample_input: Tensors, compare_fn: Callable[[TensorOrTensors, TensorOrTensors, Names], tuple[float, bool]], settings: _MinimizerSettingBase, module_exporter: Optional[Callable[[Tensors, torch.fx.GraphModule, str], None]] = ..., exclusion_fn: Optional[Callable[[NodeList, int, int], None]] = ...) -> None:
        ...
    
    def run_shape_prop(self) -> None:
        """
        Helper function to run shape propagation on module. Can be overridden by
        subclasses for custom shape propagation logic.
        """
        ...
    
    def run_a(self, mod: torch.fx.GraphModule, inputs: Tensors, report_idx: int = ...) -> TensorOrTensors:
        """
        Run `mod` with `inputs` and generate output. The output will be compared with
        output of run_b().
        """
        ...
    
    def run_b(self, mod: torch.fx.GraphModule, inputs: Tensors, report_idx: int = ...) -> TensorOrTensors:
        """
        Run `mod` with `inputs` and generate output. The output will be compared with
        output of run_a().
        """
        ...
    
    def run_nodes(self, start: Optional[str] = ..., end: Optional[str] = ...): # -> None:
        """
        Run part of the model from `start` node to `end` node. If `start` is None
        then we start from the beginning of the model. If `end` is None then we
        stop at the end of the model.

        Args:
            start: The name of the node which is the first node of the submodule
                we want to run. If set to None, then we'll start with the first
                node of the model.
            end: The name of the node which is the last node of the submodule we
                want to run. If set to None, we'll end with the last node of the
                model.
        """
        ...
    
    def print_report(self, report: list[str]): # -> None:
        ...
    
    def print_reports(self): # -> None:
        ...
    
    def minimize(self, start: Optional[str] = ..., end: Optional[str] = ..., skip_nodes: Optional[list] = ..., find_last_node: Optional[bool] = ...) -> NodeSet:
        """
        Minimizing the model from node with name `start` to node with name `end` base
        on self.settings. Find culprits that causes FxNetMinimizerRunFuncError or
        FxNetMinimizerResultMismatchError errors.

        Args:
            start: The name of the node where we want to start minimizing. If set
                to None, then we'll start with the first node of the model.
            end: The name of the node where we want to terminate minimizing. If
                set to None, we'll end with the last node of the model.
            skip_nodes: The names of nodes where we want to skip during minimizing.
                It'll create subgraphs without these skip nodes under the hood.
                Only applicable in mode "skip".
            find_last_node: True if only last_node of a culprits is needed in mode "block".
                False if only the first_node of a culprits is needed.
                Only applicable in mode "block".

        Returns:
            nodes: A list of nodes that causes FxNetMinimizerRunFuncError or
                FxNetMinimizerResultMismatchError errors during minimizing.
        """
        ...
    



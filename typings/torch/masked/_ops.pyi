"""
This type stub file was generated by pyright.
"""

from typing import Optional, TYPE_CHECKING, TypeVar, Union
from typing_extensions import ParamSpec, TypeAlias
from torch import Tensor
from torch._prims_common import DimsType
from torch.masked.maskedtensor.core import MaskedTensor
from torch.types import _dtype as DType

if TYPE_CHECKING:
    DimOrDims: TypeAlias = Optional[DimsType]
else:
    ...
__all__: list[str] = ...
_T = TypeVar("_T")
_P = ParamSpec("_P")
@_apply_docstring_templates
def sum(input: Union[Tensor, MaskedTensor], dim: DimOrDims = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

@_apply_docstring_templates
def prod(input: Union[Tensor, MaskedTensor], dim: DimOrDims = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

@_apply_docstring_templates
def cumsum(input: Tensor, dim: int, *, dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

@_apply_docstring_templates
def cumprod(input: Tensor, dim: int, *, dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

@_apply_docstring_templates
def amax(input: Union[Tensor, MaskedTensor], dim: DimOrDims = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}

{reduction_descr}

{reduction_identity_dtype}

{reduction_args}

{reduction_example}"""
    ...

@_apply_docstring_templates
def amin(input: Union[Tensor, MaskedTensor], dim: DimOrDims = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}

{reduction_descr}

{reduction_identity_dtype}

{reduction_args}

{reduction_example}"""
    ...

@_apply_docstring_templates
def argmax(input: Union[Tensor, MaskedTensor], dim: Optional[int] = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}
{reduction_descr}
{reduction_identity_dtype}
{reduction_args}
{reduction_example}"""
    ...

@_apply_docstring_templates
def argmin(input: Union[Tensor, MaskedTensor], dim: Optional[int] = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}
{reduction_descr}
{reduction_identity_dtype}
{reduction_args}
{reduction_example}"""
    ...

@_apply_docstring_templates
def mean(input: Union[Tensor, MaskedTensor], dim: DimOrDims = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}

{reduction_descr}

By definition, the identity value of a mean operation is the mean
value of the tensor. If all elements of the input tensor along given
dimension(s) :attr:`dim` are masked-out, the identity value of the
mean is undefined.  Due to this ambiguity, the elements of output
tensor with strided layout, that correspond to fully masked-out
elements, have ``nan`` values.

{reduction_args}

{reduction_example}"""
    ...

@_apply_docstring_templates
def median(input: Union[Tensor, MaskedTensor], dim: int = ..., *, keepdim: bool = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}
{reduction_descr}
By definition, the identity value of a median operation is the median
value of the tensor. If all elements of the input tensor along given
dimension(s) :attr:`dim` are masked-out, the identity value of the
median is undefined.  Due to this ambiguity, the elements of output
tensor with strided layout, that correspond to fully masked-out
elements, have ``nan`` values.
{reduction_args}
{reduction_example}"""
    ...

@_apply_docstring_templates
def logsumexp(input: Tensor, dim: DimOrDims = ..., *, keepdim: bool = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

def logaddexp(input: Union[Tensor, MaskedTensor], other: Union[Tensor, MaskedTensor], *, dtype: Optional[DType] = ..., input_mask: Optional[Tensor] = ..., other_mask: Optional[Tensor] = ...) -> Tensor:
    """logaddexp(input, other, *, dtype=None, input_mask=None, other_mask=None) -> Tensor

    Returns logaddexp of all the elements in the :attr:`input` and the :attr:`other`
    tensor. The :attr:`input` elements are masked out according to the boolean tensor
    :attr:`input_mask` and the attr:`other` elements are masked out according to the boolean tensor
    :attr:`other_mask`.

    The shapes of a mask tensor and the tensor to be masked
    don't need to match, but they must be :ref:`broadcastable
    <broadcasting-semantics>` and the dimensionality of the mask
    tensor must not be greater than of the tensor to be masked.

    Args:
        input (Tensor): the input tensor
        other (Tensor): the second input tensor

    Keyword args:
        dtype (:class:`torch.dtype`, optional): the desired data type
          of returned tensor.  If specified, the output tensor is
          casted to :attr:`dtype` after the operation is
          performed. Default: None.
        input_mask (:class:`torch.Tensor`, optional): the boolean tensor
          containing the binary mask of validity of :attr:`input` tensor elements.
          Default: None that is equivalent to ``torch.ones(input.shape, dtype=torch.bool)``.
        other_mask (:class:`torch.Tensor`, optional): the boolean tensor
          containing the binary mask of validity of :attr:`other` tensor elements.
          Default: None that is equivalent to ``torch.ones(other.shape, dtype=torch.bool)``.

    Example::

        >>> input = torch.tensor([-100.0, -200, -300])
        >>> input
        tensor([-100., -200., -300.])
        >>> other = torch.tensor([-1.0, -2, -3])
        >>> other
        tensor([-1., -2., -3.])
        >>> mask = torch.tensor([True, False, True])
        >>> mask
        tensor([ True, False,  True])
        >>> torch.masked._ops.logaddexp(input, other, input_mask=mask, other_mask=mask)
        tensor([-1., -inf, -3.])"""
    ...

@_apply_docstring_templates
def norm(input: Union[Tensor, MaskedTensor], ord: Optional[float] = ..., dim: DimOrDims = ..., *, keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}

{reduction_descr}

The identity value of norm operation, which is used to start the
reduction, is ``{identity_float32}``, except for ``ord=-inf`` it is
``{identity_ord_ninf}``.

{reduction_args}

{reduction_example}"""
    ...

@_apply_docstring_templates
def var(input: Union[Tensor, MaskedTensor], dim: DimOrDims = ..., unbiased: Optional[bool] = ..., *, correction: Optional[Union[int, float]] = ..., keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}
{reduction_descr}
The identity value of sample variance operation is undefined. The
elements of output tensor with strided layout, that correspond to
fully masked-out elements, have ``nan`` values.
{reduction_args}
{reduction_example}"""
    ...

@_apply_docstring_templates
def std(input: Union[Tensor, MaskedTensor], dim: DimOrDims = ..., unbiased: Optional[bool] = ..., *, correction: Optional[int] = ..., keepdim: Optional[bool] = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    """\
{reduction_signature}
{reduction_descr}
The identity value of sample standard deviation operation is undefined. The
elements of output tensor with strided layout, that correspond to
fully masked-out elements, have ``nan`` values.
{reduction_args}
{reduction_example}"""
    ...

@_apply_docstring_templates
def softmax(input: Union[Tensor, MaskedTensor], dim: int, *, dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

@_apply_docstring_templates
def log_softmax(input: Union[Tensor, MaskedTensor], dim: int, *, dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

@_apply_docstring_templates
def softmin(input: Union[Tensor, MaskedTensor], dim: int, *, dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...

@_apply_docstring_templates
def normalize(input: Union[Tensor, MaskedTensor], ord: float, dim: int, *, eps: float = ..., dtype: Optional[DType] = ..., mask: Optional[Tensor] = ...) -> Tensor:
    ...


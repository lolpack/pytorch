"""
This type stub file was generated by pyright.
"""

from typing import Optional, Union
from torch import Tensor
from .optimizer import Optimizer, ParamsT, _use_grad_for_differentiable

r"""Implementation for Stochastic Gradient Descent optimizer."""
__all__ = ["SGD", "sgd"]
class SGD(Optimizer):
    def __init__(self, params: ParamsT, lr: Union[float, Tensor] = ..., momentum: float = ..., dampening: float = ..., weight_decay: Union[float, Tensor] = ..., nesterov: bool = ..., *, maximize: bool = ..., foreach: Optional[bool] = ..., differentiable: bool = ..., fused: Optional[bool] = ...) -> None:
        ...
    
    def __setstate__(self, state): # -> None:
        ...
    
    @_use_grad_for_differentiable
    def step(self, closure=...): # -> None:
        """Perform a single optimization step.

        Args:
            closure (Callable, optional): A closure that reevaluates the model
                and returns the loss.
        """
        ...
    


def sgd(params: list[Tensor], d_p_list: list[Tensor], momentum_buffer_list: list[Optional[Tensor]], has_sparse_grad: bool = ..., foreach: Optional[bool] = ..., fused: Optional[bool] = ..., grad_scale: Optional[Tensor] = ..., found_inf: Optional[Tensor] = ..., *, weight_decay: float, momentum: float, lr: float, dampening: float, nesterov: bool, maximize: bool): # -> None:
    r"""Functional API that performs SGD algorithm computation.

    See :class:`~torch.optim.SGD` for details.
    """
    ...


"""
This type stub file was generated by pyright.
"""

import dataclasses
import types
import torch.nn
from typing import Optional, TYPE_CHECKING
from .bytecode_transformation import Instruction
from .source import Source
from .variables.base import VariableTracker
from .symbolic_convert import InstructionTranslatorBase

"""
This module provides utilities for generating Python bytecode in PyTorch's Dynamo system.
It includes functionality for:
- Constructing bytecode sequences for Python operations
- Managing stack operations and variable tracking
- Handling graph outputs and their conversions
- Supporting different Python versions (3.11+, 3.12+, 3.13+)
- Converting high-level operations to low-level bytecode instructions
- Managing constant loading and attribute access
- Supporting function creation and closure handling
"""
if TYPE_CHECKING:
    ...
@dataclasses.dataclass
class GraphOutputEntry:
    index: int
    variable: VariableTracker
    ...


class PyCodegen:
    """
    Helper class uses for constructing Python bytecode
    """
    def __init__(self, tx: InstructionTranslatorBase, root: Optional[torch.nn.Module] = ..., graph_output_var: Optional[str] = ..., tempvars=..., overridden_sources=...) -> None:
        ...
    
    def restore_stack(self, stack_values, *, value_from_source=...): # -> None:
        ...
    
    def graph_output_vars(self): # -> list[VariableTracker]:
        ...
    
    def call_reconstruct(self, value): # -> None:
        ...
    
    def add_push_null(self, gen_fn, call_function_ex=...): # -> None:
        """
        `gen_fn` generates instructions via PyCodegen methods
        that push a single callable to the stack.

        `add_push_null` pushes a NULL to the stack before or after the
        instructions generated by `gen_fn`, depending on Python version.

        Will attempt to use the NULL push bit for instructions
        with such bits (LOAD_GLOBAL 3.11+, LOAD_ATTR 3.12+, LOAD_SUPER_ATTR).
        """
        ...
    
    def __call__(self, value, allow_cache=...):
        """
        Generate code such that top-of-stack (TOS) is set to value.

        `allow_cache` controls the behavior in the following manner. `value` can
        either be a VariableTracker or a Source.

        If `value` is a `Source`, `allow_cache` must be True (invariant asserted
        below). If the source was reconstructed earlier, we will reuse the
        generated code by loading from top of stack or tempvars.

        If `value` is a `VariableTracker`, we have the following cases:

        1) `allow_cache=True`
            a) If the value.source is not None, we will emit the code based on
            `value.source` to handle aliasing.
            b) If value.source is None (example reconstructing a local list
            returned by the compiled function), we will reconstruct the variable
            tracker (w/o any source) to emit bytecode that generates a new
            python object.

            In both cases of value.source being None or not, if the value was
            reconstructed earlier, we will reuse the generated code by loading from
            top of stack or tempvars.

        2) `allow_cache=False` - This is a special case (allow_cache defaults to
        True).
            a) If the value.source is not None, we reconstruct the variable
            tracker and emit a new python object. You might wonder what about
            aliasing? The place where we use this config also has the followup
            code where the original python object is assigned to this new python
            value to handle aliasing (check side_effects.py and search for
            allow_cache=False).

            b) If value.source is None, this is not allowed. TODO - assert this.

        Notable effects:
        1. `self.top_of_stack` will be set to `value`, if we don't codegen
           `value` based on source.
        2. `self.uses[value]` will increment, unless (a). we codegen via
            `top_of_stack` or cached `tempvars`, or (b). `value` has special VT
            types like `NNModuleVariable`, etc.
        """
        ...
    
    def add_graph_output(self, value): # -> int:
        ...
    
    def load_graph_output(self, index): # -> None:
        ...
    
    def add_cache(self, value): # -> None:
        ...
    
    def foreach(self, items): # -> None:
        ...
    
    def create_binary_subscr(self) -> Instruction:
        ...
    
    def setup_globally_cached(self, name, value): # -> list[DataclassInstance]:
        """Store value in a new global"""
        ...
    
    def clear_tos(self): # -> None:
        ...
    
    def append_output(self, inst): # -> None:
        ...
    
    def extend_output(self, insts): # -> None:
        ...
    
    def get_instructions(self) -> list[Instruction]:
        ...
    
    def create_load(self, name) -> Instruction:
        ...
    
    def create_load_closure(self, name) -> Instruction:
        ...
    
    def create_load_deref(self, name) -> Instruction:
        ...
    
    def create_store(self, name) -> Instruction:
        ...
    
    def create_store_deref(self, name) -> Instruction:
        ...
    
    def create_load_global(self, name, add=...) -> Instruction:
        ...
    
    def create_load_const(self, value) -> Instruction:
        ...
    
    def create_load_const_unchecked(self, value) -> Instruction:
        ...
    
    def load_method(self, name): # -> None:
        ...
    
    def call_method(self, nargs): # -> None:
        ...
    
    def create_load_attr(self, name) -> Instruction:
        ...
    
    def load_attr(self, name): # -> None:
        ...
    
    def create_load_attrs(self, names): # -> list[DataclassInstance]:
        ...
    
    def create_store_attr(self, name) -> Instruction:
        ...
    
    def store_attr(self, name): # -> None:
        ...
    
    def load_function_name(self, fn_name, push_null, num_on_stack=...): # -> list[Any]:
        """Load the global fn_name on the stack num_on_stack down"""
        ...
    
    def rot_n(self, n): # -> list[DataclassInstance]:
        ...
    
    def pop_top(self): # -> None:
        ...
    
    def call_function(self, nargs: int, push_null: bool): # -> None:
        ...
    
    def dup_top(self): # -> None:
        ...
    
    def store(self, varname): # -> None:
        ...
    
    def load_deref(self, varname): # -> None:
        ...
    
    def make_function_with_closure(self, fn_name: str, code: types.CodeType, push_null: bool, num_on_stack=...): # -> None:
        ...
    
    def create_load_python_module(self, mod) -> Instruction:
        """
        Generate a LOAD_GLOBAL instruction to fetch a given python module.
        """
        ...
    
    def mark_source_temp(self, source: Source) -> None:
        """
        Mark a source as a temp variable, so that it can be reused.
        """
        ...
    
    def make_call_generated_code(self, fn_name: str) -> None:
        """Call the generated code function stored in fn_name"""
        ...
    
    def load_import_from(self, module_name, object_name) -> None:
        ...
    
    def create_call_function_kw(self, nargs, kw_names, push_null) -> list[Instruction]:
        ...
    
    def create_delete(self, value) -> Instruction:
        ...
    



"""
This type stub file was generated by pyright.
"""

import dataclasses
import types
from typing import Any, Optional
from .bytecode_transformation import Instruction

"""
This module provides functionality for resuming Python execution at specific points in code,
primarily used by PyTorch Dynamo for control flow handling and optimization. It implements
bytecode transformation and execution state management to enable:

- Resuming execution at arbitrary points in Python bytecode
- Managing context managers and their state across execution boundaries
- Transforming and generating new code objects with preserved execution state
- Supporting Python 3.11+ exception handling and block management
- Restoring torch function mode stacks and other execution context

The module is critical for PyTorch Dynamo's ability to optimize code while preserving
Python semantics and execution state.
"""
CO_OPTIMIZED = ...
CO_NEWLOCALS = ...
CO_VARARGS = ...
CO_VARKEYWORDS = ...
CO_NESTED = ...
CO_GENERATOR = ...
CO_NOFREE = ...
CO_COROUTINE = ...
CO_ITERABLE_COROUTINE = ...
CO_ASYNC_GENERATOR = ...
TORCH_DYNAMO_RESUME_IN_PREFIX = ...
IS_TRACING_RESUME_PROLOGUE_VARNAME = ...
@dataclasses.dataclass(frozen=True)
class ReenterWith:
    stack_index: int
    target_values: Optional[tuple[Any, ...]] = ...
    def try_except_torch_function_mode(self, code_options, cleanup: list[Instruction]): # -> list[DataclassInstance]:
        """
        Codegen based off of:
        try:
            (rest)
        except:
            (restore previous tf mode stack)
            raise
        """
        ...
    
    def try_finally(self, code_options, cleanup: list[Instruction]): # -> list[DataclassInstance]:
        """
        Codegen based off of:
        load args
        enter context
        try:
            (rest)
        finally:
            exit context
        """
        ...
    
    def __call__(self, code_options, cleanup): # -> tuple[list[DataclassInstance], DataclassInstance | None]:
        """
        Codegen based off of:
        with ctx(args):
            (rest)
        """
        ...
    


@dataclasses.dataclass
class ResumeFunctionMetadata:
    code: types.CodeType
    instructions: list[Instruction] = ...
    prefix_block_target_offset_remap: list[int] = ...
    block_target_offset_remap: Optional[dict[int, int]] = ...


class ContinueExecutionCache:
    cache = ...
    generated_code_metadata = ...
    @classmethod
    def lookup(cls, code, lineno, *key):
        ...
    
    @classmethod
    def generate(cls, code, lineno, offset: int, setup_fn_target_offsets: tuple[int, ...], nstack: int, argnames: tuple[str, ...], argnames_null: tuple[str, ...], setup_fns: tuple[ReenterWith, ...], stack_ctx_vars: tuple[tuple[int, tuple[Any, ...]], ...], argnames_ctx_vars: tuple[tuple[str, tuple[Any, ...]], ...], null_idxes: tuple[int, ...]) -> types.CodeType:
        ...
    
    @staticmethod
    def unreachable_codes(code_options) -> list[Instruction]:
        """Codegen a `raise None` to make analysis work for unreachable code"""
        ...
    
    @classmethod
    def generate_based_on_original_code_object(cls, code, lineno, offset: int, setup_fn_target_offsets: tuple[int, ...], *args):
        """
        This handles the case of generating a resume into code generated
        to resume something else.  We want to always generate starting
        from the original code object so that if control flow paths
        converge we only generated 1 resume function (rather than 2^n
        resume functions).
        """
        ...
    



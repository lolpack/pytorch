"""
This type stub file was generated by pyright.
"""

import functools
from collections.abc import Sequence
from typing import Any, Callable, Optional, TYPE_CHECKING
from ..codegen import PyCodegen
from .base import VariableTracker
from torch._dynamo.symbolic_convert import InstructionTranslator

"""
This module implements variable tracking for torch functions and operations during Dynamo tracing.

It provides classes to handle different types of torch operations:

TorchInGraphFunctionVariable: Handles torch.* functions that should be captured in the FX graph.
Provides special handling for constant folding, tensor methods, and torch function overrides.
Manages complex cases like out= variants and parameter construction.

TorchCtxManagerClassVariable: Handles torch context managers like torch.no_grad(), autocast, etc.
Provides implementations for entering/exiting these contexts during tracing.

DispatchKeySetVariable: Represents torch.DispatchKeySet for managing dispatch keys and
device-specific operations during tracing.

The module includes special handling for:
- Constant folding of pure functions
- Tensor method calls
- torch.nn.Parameter construction
- __torch_function__ overrides
- Context manager state tracking
- Device and dtype management

This is a core part of Dynamo's tracing system, translating torch operations into
traceable graph nodes while preserving correct semantics and handling edge cases.
"""
if TYPE_CHECKING:
    ...
log = ...
supported_ctx_manager_classes = ...
REWRITE_OPS_TO_TENSOR_SIZE_METHOD = ...
constant_fold_functions_need_guards = ...
constant_fold_functions = ...
if torch.distributed.is_available():
    ...
constant_fold_functions_need_guards = ...
constant_fold_functions = ...
@functools.cache
def tracing_state_functions() -> dict[Callable[[], Any], Optional[bool]]:
    ...

bin_ops = ...
dispatch_key_set_functions = ...
@functools.cache
def get_overridable_functions(): # -> set[Callable[..., Any]]:
    ...

class BaseTorchVariable(VariableTracker):
    """common base for all torch.* functions, classes, modules and other things"""
    @classmethod
    def create_with_source(cls, value, source): # -> Self:
        ...
    
    def __init__(self, value, **kwargs) -> None:
        ...
    
    def reconstruct(self, codegen: PyCodegen): # -> None:
        ...
    
    def as_proxy(self): # -> Any:
        ...
    
    def as_python_constant(self): # -> Any:
        ...
    
    def call_obj_hasattr(self, tx: InstructionTranslator, name): # -> VariableTracker:
        ...
    
    def can_constant_fold_through(self): # -> Any | Literal[True]:
        ...
    


class TorchCtxManagerClassVariable(BaseTorchVariable):
    """Points to a context manager class in torch.* that dynamo has implementations"""
    def __repr__(self) -> str:
        ...
    
    @staticmethod
    def is_matching_cls(value): # -> TypeIs[Callable[..., object]] | bool:
        ...
    
    def call_function(self, tx: InstructionTranslator, args: Sequence[VariableTracker], kwargs: dict[str, VariableTracker]) -> VariableTracker:
        ...
    


class TorchInGraphFunctionVariable(BaseTorchVariable):
    """Points to a torch function/method that should be put in FX graph"""
    def __init__(self, value, nonstrict_traceable=..., **kwargs) -> None:
        ...
    
    def __repr__(self) -> str:
        ...
    
    def get_function(self): # -> Any:
        ...
    
    def call_function(self, tx: InstructionTranslator, args: Sequence[VariableTracker], kwargs: dict[str, VariableTracker]) -> VariableTracker:
        ...
    
    @classmethod
    def call_nn_parameter(cls, tx, data=..., requires_grad=...): # -> Any | TensorVariable:
        """A call to torch.nn.Parameter() gets lifted to before the graph"""
        ...
    
    def call_tensor_method(self, tx, args, kwargs):
        ...
    
    def is_tensor_method(self): # -> TypeIs[MethodDescriptorType] | bool:
        ...
    
    def torch_function_override_enabled(self, tx, args, kwargs): # -> bool:
        ...
    


class DispatchKeySetVariable(BaseTorchVariable):
    """represents torch.DispatchKeySet"""
    @staticmethod
    def create(value, **kwargs): # -> DispatchKeySetVariable:
        ...
    
    @classmethod
    def create_with_source(cls, value, source): # -> Self:
        ...
    
    def is_constant_fold_method(self, name): # -> bool:
        ...
    
    def call_method(self, tx, name, args: list[VariableTracker], kwargs: dict[str, VariableTracker]) -> VariableTracker:
        ...
    


class FuncTorchInterpreterVariable(BaseTorchVariable):
    """represents torch._functorch.pyfunctorch.FuncTorchInterpreter"""
    @classmethod
    def create_with_source(cls, value, source): # -> Self:
        ...
    
    def call_method(self, tx, name, args: list[VariableTracker], kwargs: dict[str, VariableTracker]) -> VariableTracker:
        ...
    



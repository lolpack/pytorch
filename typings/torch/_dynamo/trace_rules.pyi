"""
This type stub file was generated by pyright.
"""

import dataclasses
import functools
import sys
import types
import typing
import torch
import torch.distributed
import numpy as np
from typing import Any, Callable, Optional, Union
from .variables.base import VariableTracker

"""
Tracing rules and policies for TorchDynamo compilation decisions.

This module defines the rules that govern what code TorchDynamo should trace and compile
versus what should be executed eagerly. It contains functions and classes that determine:

- Which modules, functions, and objects should be skipped during tracing
- Which parts of the code should cause graph breaks
- How to handle different Python libraries and third-party packages
- Rules for determining when to inline functions vs calling them eagerly

Key components:
- Skip rules: Functions that return True if an object should be skipped during tracing
- Inlining rules: Policies for when to inline function calls during compilation
- Library-specific handling: Special cases for popular Python packages
- Performance heuristics: Rules that balance compilation overhead vs runtime benefits

These rules are critical for TorchDynamo's ability to automatically determine
compilation boundaries and optimize PyTorch programs effectively.
"""
np: Optional[types.ModuleType] = ...
if typing.TYPE_CHECKING:
    ...
manual_torch_name_rule_map: dict[str, Any] = ...
torch_c_binding_in_graph_functions = ...
if sys.version_info >= (3, 11):
    ...
torch_non_c_binding_in_graph_functions = ...
torch_name_rule_map = ...
@functools.cache
def get_torch_obj_rule_map() -> dict[Any, type[VariableTracker]]:
    ...

def load_object(name): # -> Any | FunctionType | BuiltinFunctionType | MethodDescriptorType | WrapperDescriptorType | None:
    ...

@functools.cache
def get_tensor_method(): # -> frozenset[Any]:
    ...

def is_aten_op_or_tensor_method(obj): # -> bool:
    ...

class FunctionIdSet:
    """
    Track a set of `id()`s of objects which are either allowed or not
    allowed to go into the generated FX graph.  Use to test for torch.*,
    numpy.*, builtins.*, etc.

    Support user modification to permit customization of what can be
    added to the graph and what will cause a graph break.
    """
    function_ids: Optional[set[int]] = ...
    function_names: Optional[dict[int, str]] = ...
    def __init__(self, lazy_initializer: Callable[[], Union[dict[int, str], set[int]]]) -> None:
        ...
    
    def __call__(self) -> set[int]:
        ...
    
    def get_name(self, idx: int, default: str): # -> str:
        ...
    
    def add(self, idx: int): # -> None:
        ...
    
    def remove(self, idx: int): # -> None:
        ...
    
    def __contains__(self, idx: int) -> bool:
        ...
    


_lazy_module_init: dict[str, list[Callable[[], None]]] = ...
def add_module_init_func(name: str, init_func: Callable[[], None]) -> None:
    """Register a module without eagerly importing it"""
    ...

def is_callable_allowed(obj) -> bool:
    ...

def is_nonstrict_trace_callable(obj) -> bool:
    ...

def is_callable_disallowed(obj) -> bool:
    ...

def is_forbidden(obj) -> bool:
    ...

def is_builtin_callable(obj) -> bool:
    ...

def is_builtin_constant(obj) -> bool:
    ...

def is_polyfilled_callable(obj) -> bool:
    ...

def is_numpy(obj) -> bool:
    ...

def is_numpy_dtype(obj) -> bool:
    ...

def is_numpy_type_info(obj) -> bool:
    ...

BUILTIN_SKIPLIST = ...
THIRDPARTY_SKIPLIST = ...
LEGACY_MOD_INLINELIST = ...
if torch.distributed.is_available():
    ...
MOD_INLINELIST = ...
MOD_INLINELIST = ...
if torch.distributed.is_available():
    ...
MOD_SKIPLIST = ...
MOD_SKIPLIST = ...
@functools.cache
def get_legacy_mod_inlinelist(): # -> set[str]:
    ...

@functools.cache
def get_mod_inlinelist(): # -> set[str]:
    ...

@functools.cache
def get_mod_skiplist(): # -> set[str]:
    ...

SKIP_DIRS = ...
SKIP_DIRS_RE = ...
FBCODE_SKIP_DIRS: set[str] = ...
FBCODE_SKIP_DIRS_RE = ...
FBCODE_SKIP_TORCHREC_DIRS = ...
FBCODE_SKIP_TORCHREC_DIRS_RE = ...
FBCODE_INLINE_FILES_IN_SKIPPED_DIRS = ...
FBCODE_INLINE_FILES_IN_SKIPPED_DIRS_RE = ...
FORCE_SKIP_FILES = ...
def add(import_name: str): # -> None:
    ...

@dataclasses.dataclass
class SkipResult:
    skipped: bool
    reason: Optional[str]
    ...


def check_file(filename, is_inlined_call=...): # -> SkipResult:
    """Should skip this file?"""
    ...

@dataclasses.dataclass
class FunctionInfo:
    py_obj: Optional[object]
    name: Optional[str]
    filename: str
    code: Optional[types.CodeType]
    ...


def check_verbose(obj, is_inlined_call=...): # -> SkipResult:
    ...

def check(obj, is_inlined_call=...): # -> bool:
    ...

def is_torch_inline_allowed(filename): # -> bool:
    ...

@functools.cache
def dynamo_dir(): # -> Any | str | None:
    ...

def is_torch(filename): # -> Literal[False]:
    ...

def lookup_callable(obj): # -> type[SkipFunctionVariable] | type[TorchInGraphFunctionVariable] | type[PolyfilledFunctionVariable] | type[BuiltinVariable] | None:
    ...

def lookup(obj): # -> type[SkipFunctionVariable] | type[UserFunctionVariable] | type[TorchInGraphFunctionVariable] | type[VariableTracker] | None:
    ...

def lookup_inner(obj, name=..., filename=..., is_direct_call=..., reasons: Union[None, set[str]] = ...): # -> type[SkipFunctionVariable] | type[UserFunctionVariable] | type[TorchInGraphFunctionVariable] | type[VariableTracker] | None:
    ...

def clear_lru_cache(): # -> None:
    ...


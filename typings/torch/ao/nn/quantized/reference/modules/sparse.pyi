"""
This type stub file was generated by pyright.
"""

import torch.nn as nn
from typing import Any, Optional
from torch import Tensor
from .utils import ReferenceQuantizedModule

__all__ = ["Embedding", "EmbeddingBag"]
class Embedding(nn.Embedding, ReferenceQuantizedModule):
    """A reference quantized Embedding module that fits into the
    FX Graph Mode Quantization workflow, activation will be floating point Tensor,
    we will store floating point weight as well in the module, but in forward we'll
    quantize and dequantize the weight before running the floating point functional
    embedding operator.
    """
    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = ..., max_norm: Optional[float] = ..., norm_type: float = ..., scale_grad_by_freq: bool = ..., sparse: bool = ..., _weight: Optional[Tensor] = ..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, input: Tensor) -> Tensor:
        ...
    
    @classmethod
    def from_float(cls, mod, weight_qparams): # -> Self:
        ...
    


class EmbeddingBag(nn.EmbeddingBag, ReferenceQuantizedModule):
    """A reference quantized EmbeddingBag module that fits into the
    FX Graph Mode Quantization workflow, activation will be floating point Tensor,
    we will store floating point weight as well in the module, but in forward we'll
    quantize and dequantize the weight before running the floating point functional
    embedding operator.
    """
    def __init__(self, num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = ..., norm_type: float = ..., scale_grad_by_freq: bool = ..., mode: str = ..., sparse: bool = ..., _weight: Optional[Tensor] = ..., include_last_offset: bool = ..., padding_idx: Optional[int] = ..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, input: Tensor, offsets: Optional[Tensor] = ..., per_sample_weights: Optional[Tensor] = ...) -> Tensor:
        ...
    
    @classmethod
    def from_float(cls, mod, weight_qparams, use_precomputed_fake_quant=...): # -> Self:
        ...
    



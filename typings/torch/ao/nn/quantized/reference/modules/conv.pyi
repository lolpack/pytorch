"""
This type stub file was generated by pyright.
"""

import torch
import torch.nn as nn
from typing import Any, Optional
from torch.nn.common_types import _size_1_t
from .utils import ReferenceQuantizedModule

__all__ = ["Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d"]
class _ConvNd(torch.nn.modules.conv._ConvNd, ReferenceQuantizedModule):
    """A reference version of nn.quantized.Conv2d
    we will not pack the parameters in this module, since weight packing is an
    optimization for quantized backends supported in PyTorch (fbgemm/qnnpack),
    this is useful when user want to use this module in other backends like Glow.
    """
    __annotations__ = ...
    _IS_REFERENCE = ...
    @staticmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    


class Conv1d(_ConvNd, nn.Conv1d):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: _size_1_t, stride: _size_1_t = ..., padding: _size_1_t = ..., dilation: _size_1_t = ..., groups: int = ..., bias: bool = ..., padding_mode: str = ..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        we have:
        w(float) -- quant - dequant \
        x(float) ------------- F.conv1d ---

        In the full model, we will see
        w(float) -- quant - *dequant \
        x -- quant --- *dequant --  *F.conv1d --- *quant - dequant
        and the backend should be able to fuse the ops with `*` into a quantized conv1d
        """
        ...
    
    @classmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    


class Conv2d(_ConvNd, nn.Conv2d):
    def __init__(self, in_channels, out_channels, kernel_size, stride=..., padding=..., dilation=..., groups=..., bias=..., padding_mode=..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        we have:
        w(float) -- quant - dequant \
        x(float) ------------- F.conv2d ---

        In the full model, we will see
        w(float) -- quant - *dequant \
        x -- quant --- *dequant --  *F.conv2d --- *quant - dequant
        and the backend should be able to fuse the ops with `*` into a quantized conv2d
        """
        ...
    
    @classmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    


class Conv3d(_ConvNd, nn.Conv3d):
    def __init__(self, in_channels, out_channels, kernel_size, stride=..., padding=..., dilation=..., groups=..., bias=..., padding_mode=..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        we have:
        w(float) -- quant - dequant \
        x(float) ------------- F.conv3d ---

        In the full model, we will see
        w(float) -- quant - *dequant \
        x -- quant --- *dequant --  *F.conv3d --- *quant - dequant
        and the backend should be able to fuse the ops with `*` into a quantized conv3d
        """
        ...
    
    @classmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    


class _ConvTransposeNd(_ConvNd, torch.nn.modules.conv._ConvTransposeNd):
    """A reference version of nn.quantized.ConvTranspose2d
    we will not pack the parameters in this module, since weight packing is an
    optimization for quantized backends supported in PyTorch (fbgemm/qnnpack),
    this is useful when user want to use this module in other backends like Glow.
    """
    @staticmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    


class ConvTranspose1d(_ConvTransposeNd, nn.ConvTranspose1d):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: _size_1_t, stride: _size_1_t = ..., padding: _size_1_t = ..., output_padding: _size_1_t = ..., groups: int = ..., bias: bool = ..., dilation: _size_1_t = ..., padding_mode: str = ..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, x: torch.Tensor, output_size: Optional[list[int]] = ...) -> torch.Tensor:
        """
        we have:
        w(float) -- quant - dequant \
        x(float) ------------- F.convTranspose1d ---
        In the full model, we will see
        w(float) -- quant - *dequant \
        x -- quant --- *dequant --  *F.convTranspose1d --- *quant - dequant
        and the backend should be able to fuse the ops with `*` into a quantized conv1d
        """
        ...
    
    @classmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    


class ConvTranspose2d(_ConvTransposeNd, nn.ConvTranspose2d):
    def __init__(self, in_channels, out_channels, kernel_size, stride=..., padding=..., output_padding=..., groups=..., bias=..., dilation=..., padding_mode=..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, x: torch.Tensor, output_size: Optional[list[int]] = ...) -> torch.Tensor:
        """
        we have:
        w(float) -- quant - dequant \
        x(float) ------------- F.convTranspose2d ---
        In the full model, we will see
        w(float) -- quant - *dequant \
        x -- quant --- *dequant --  *F.convTranspose2d --- *quant - dequant
        and the backend should be able to fuse the ops with `*` into a quantized conv2d
        """
        ...
    
    @classmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    


class ConvTranspose3d(_ConvTransposeNd, nn.ConvTranspose3d):
    def __init__(self, in_channels, out_channels, kernel_size, stride=..., padding=..., output_padding=..., groups=..., bias=..., dilation=..., padding_mode=..., device=..., dtype=..., weight_qparams: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, x: torch.Tensor, output_size: Optional[list[int]] = ...) -> torch.Tensor:
        """
        we have:
        w(float) -- quant - dequant \
        x(float) ------------- F.convTranspose3d ---
        In the full model, we will see
        w(float) -- quant - *dequant \
        x -- quant --- *dequant --  *F.convTranspose3d --- *quant - dequant
        and the backend should be able to fuse the ops with `*` into a quantized conv3d
        """
        ...
    
    @classmethod
    def from_float(cls, float_conv, weight_qparams):
        ...
    



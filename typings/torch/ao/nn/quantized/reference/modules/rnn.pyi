"""
This type stub file was generated by pyright.
"""

import torch.nn as nn
from typing import Any, Optional
from torch import Tensor

__all__ = ["RNNCellBase", "RNNCell", "LSTMCell", "GRUCell", "RNNBase", "LSTM", "GRU", "get_quantized_weight"]
def get_quantized_weight(module, wn): # -> Tensor | None:
    ...

class RNNCellBase(nn.RNNCellBase):
    def __init__(self, input_size: int, hidden_size: int, bias: bool, num_chunks: int, device=..., dtype=..., weight_qparams_dict=...) -> None:
        ...
    
    def get_quantized_weight_ih(self): # -> Tensor | None:
        ...
    
    def get_quantized_weight_hh(self): # -> Tensor | None:
        ...
    
    def get_weight_ih(self): # -> Tensor | None:
        ...
    
    def get_weight_hh(self): # -> Tensor | None:
        ...
    


class RNNCell(RNNCellBase):
    """
    We'll store weight_qparams for all the weights (weight_ih and weight_hh),
    we need to pass in a `weight_qparams_dict` that maps from weight name,
    e.g. weight_ih, to the weight_qparams for that weight
    """
    def __init__(self, input_size: int, hidden_size: int, bias: bool = ..., nonlinearity: str = ..., device=..., dtype=..., weight_qparams_dict: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, input: Tensor, hx: Optional[Tensor] = ...) -> Tensor:
        ...
    
    @classmethod
    def from_float(cls, mod, weight_qparams_dict): # -> Self:
        ...
    


class LSTMCell(RNNCellBase):
    """
    We'll store weight_qparams for all the weights (weight_ih and weight_hh),
    we need to pass in a `weight_qparams_dict` that maps from weight name,
    e.g. weight_ih, to the weight_qparams for that weight
    """
    def __init__(self, input_size: int, hidden_size: int, bias: bool = ..., device=..., dtype=..., weight_qparams_dict: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, input: Tensor, hx: Optional[tuple[Tensor, Tensor]] = ...) -> tuple[Tensor, Tensor]:
        ...
    
    @classmethod
    def from_float(cls, mod, weight_qparams_dict, use_precomputed_fake_quant=...): # -> Self:
        ...
    


class GRUCell(RNNCellBase):
    """
    We'll store weight_qparams for all the weights (weight_ih and weight_hh),
    we need to pass in a `weight_qparams_dict` that maps from weight name,
    e.g. weight_ih, to the weight_qparams for that weight
    """
    def __init__(self, input_size: int, hidden_size: int, bias: bool = ..., device=..., dtype=..., weight_qparams_dict: Optional[dict[str, Any]] = ...) -> None:
        ...
    
    def forward(self, input: Tensor, hx: Optional[Tensor] = ...) -> Tensor:
        ...
    
    @classmethod
    def from_float(cls, mod, weight_qparams_dict): # -> Self:
        ...
    


class RNNBase(nn.RNNBase):
    def __init__(self, mode: str, input_size: int, hidden_size: int, num_layers: int = ..., bias: bool = ..., batch_first: bool = ..., dropout: float = ..., bidirectional: bool = ..., proj_size: int = ..., device=..., dtype=..., weight_qparams_dict: Optional[dict[str, Any]] = ...) -> None:
        ...
    


class LSTM(RNNBase):
    """Reference Quantized LSTM Module
    We'll store weight_qparams for all the weights in _flat_weights, we need to pass in
    a `weight_qparams_dict` that maps from weight name, e.g. weight_ih_l0,
    to the weight_qparams for that weight
    """
    def __init__(self, *args, **kwargs) -> None:
        ...
    
    def permute_hidden(self, hx: tuple[Tensor, Tensor], permutation: Optional[Tensor]) -> tuple[Tensor, Tensor]:
        ...
    
    def get_expected_cell_size(self, input: Tensor, batch_sizes: Optional[Tensor]) -> tuple[int, int, int]:
        ...
    
    def check_forward_args(self, input: Tensor, hidden: tuple[Tensor, Tensor], batch_sizes: Optional[Tensor]): # -> None:
        ...
    
    def get_quantized_weight_bias_dict(self): # -> dict[Any, Any]:
        """dictionary from flat_weight_name to quantized weight or (unquantized) bias
        e.g.
        {
          "weight_ih_l0": quantized_weight,
          "bias_ih_l0": unquantized_bias,
          ...
        }
        """
        ...
    
    def get_flat_weights(self): # -> list[Any]:
        ...
    
    def forward(self, input, hx=...): # -> tuple[PackedSequence, tuple[Tensor, Tensor]] | tuple[Any, tuple[Tensor, Tensor]]:
        ...
    
    @classmethod
    def from_float(cls, mod, weight_qparams_dict): # -> Self:
        ...
    


class GRU(RNNBase):
    """Reference Quantized GRU Module
    We'll store weight_qparams for all the weights in _flat_weights, we need to pass in
    a `weight_qparams_dict` that maps from weight name, e.g. weight_ih_l0,
    to the weight_qparams for that weight
    """
    def __init__(self, *args, **kwargs) -> None:
        ...
    
    def get_quantized_weight_bias_dict(self): # -> dict[Any, Any]:
        """dictionary from flat_weight_name to quantized weight or (unquantized) bias
        e.g.
        {
          "weight_ih_l0": quantized_weight,
          "bias_ih_l0": unquantized_bias,
          ...
        }
        """
        ...
    
    def get_flat_weights(self): # -> list[Any]:
        ...
    
    def forward(self, input, hx=...): # -> tuple[PackedSequence, Tensor] | tuple[Any, Tensor]:
        ...
    
    @classmethod
    def from_float(cls, mod, weight_qparams_dict): # -> Self:
        ...
    



"""
This type stub file was generated by pyright.
"""

import torch.nn as nn
from torch import Tensor

__all__ = ["Embedding", "EmbeddingBag"]
class Embedding(nn.Embedding):
    r"""
    An embedding bag module attached with FakeQuantize modules for weight,
    used for quantization aware training.

    We adopt the same interface as `torch.nn.Embedding`, please see
    https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding
    for documentation.

    Similar to `torch.nn.Embedding`, with FakeQuantize modules initialized to
    default.

    Attributes:
        weight: fake quant module for weight
    """
    _FLOAT_MODULE = nn.Embedding
    def __init__(self, num_embeddings, embedding_dim, padding_idx=..., max_norm=..., norm_type=..., scale_grad_by_freq=..., sparse=..., _weight=..., device=..., dtype=..., qconfig=...) -> None:
        ...
    
    def forward(self, input) -> Tensor:
        ...
    
    @classmethod
    def from_float(cls, mod, use_precomputed_fake_quant=...): # -> Self:
        r"""Create a qat module from a float module

        Args: `mod` a float module, either produced by torch.ao.quantization utilities
        or directly from user
        """
        ...
    
    def to_float(self): # -> Embedding:
        ...
    


class EmbeddingBag(nn.EmbeddingBag):
    r"""
    An embedding bag module attached with FakeQuantize modules for weight,
    used for quantization aware training.

    We adopt the same interface as `torch.nn.EmbeddingBag`, please see
    https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag
    for documentation.

    Similar to `torch.nn.EmbeddingBag`, with FakeQuantize modules initialized to
    default.

    Attributes:
        weight: fake quant module for weight
    """
    _FLOAT_MODULE = nn.EmbeddingBag
    def __init__(self, num_embeddings, embedding_dim, max_norm=..., norm_type=..., scale_grad_by_freq=..., mode=..., sparse=..., _weight=..., include_last_offset=..., padding_idx=..., qconfig=..., device=..., dtype=...) -> None:
        ...
    
    def forward(self, input, offsets=..., per_sample_weights=...) -> Tensor:
        ...
    
    @classmethod
    def from_float(cls, mod, use_precomputed_fake_quant=...): # -> Self:
        r"""Create a qat module from a float module

        Args: `mod` a float module, either produced by torch.ao.quantization utilities
        or directly from user
        """
        ...
    
    def to_float(self): # -> EmbeddingBag:
        ...
    


